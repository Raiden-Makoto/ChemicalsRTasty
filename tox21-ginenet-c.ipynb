{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["VC6dgzIvNpYm","JLWC-e33ywAM","0E9B-fNYOB3q","rQFEcuNXpE8C"],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tox21 GINENet\n\nWe’re solving a multi-task binary toxicity prediction problem on Tox21. Concretely, for each molecule the model outputs 12 probabilities, one for each assay (e.g. NR-AR, SR-ARE, p53, etc.). At training time we use a binary cross-entropy loss (with masking for missing labels) over those 12 tasks, and at the end of each epoch we compute the ROC-AUC per task (then average) on the held-out validation set to see how well the model is distinguishing actives vs. inactives across all assays.","metadata":{"id":"VC6dgzIvNpYm"}},{"cell_type":"code","source":"%pip -q install rdkit-pypi torch_geometric","metadata":{"id":"l0Z81NMxoiW9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e17f73e4-4830-4b56-b3bc-34550217458f","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:17:17.716893Z","iopub.execute_input":"2025-05-27T00:17:17.717090Z","iopub.status.idle":"2025-05-27T00:17:25.255865Z","shell.execute_reply.started":"2025-05-27T00:17:17.717072Z","shell.execute_reply":"2025-05-27T00:17:25.255008Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Subset, WeightedRandomSampler\nfrom torch.serialization import safe_globals, add_safe_globals\n\n# Pytorch Geometric Imports\nfrom torch_geometric.data import InMemoryDataset, Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.data.data import DataTensorAttr, DataEdgeAttr\nfrom torch_geometric.data.storage import GlobalStorage\nfrom torch_geometric.nn import (\n    GINEConv,\n    GatedGraphConv,\n    Set2Set,\n    GlobalAttention,\n    global_add_pool\n)\nfrom torch_geometric.nn.models import JumpingKnowledge\n\n# RDKit Imports\nfrom rdkit.Chem.Scaffolds import MurckoScaffold\nfrom rdkit.Chem import MolFromSmiles, MolToSmiles, rdchem\n\nfrom sklearn.metrics import roc_auc_score\nimport os","metadata":{"id":"TmEESHMxt72N","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:27:34.637162Z","iopub.execute_input":"2025-05-27T00:27:34.638003Z","iopub.status.idle":"2025-05-27T00:27:34.644286Z","shell.execute_reply.started":"2025-05-27T00:27:34.637956Z","shell.execute_reply":"2025-05-27T00:27:34.643346Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"!wget wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/tox21.csv.gz\n!gunzip tox21.csv.gz\n!mkdir -p raw\n!mv tox21.csv raw/","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4dsjviCYyJpu","outputId":"1df76760-1456-4190-c35e-e668485b0878","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:21:31.872548Z","iopub.execute_input":"2025-05-27T00:21:31.872937Z","iopub.status.idle":"2025-05-27T00:21:32.667684Z","shell.execute_reply.started":"2025-05-27T00:21:31.872917Z","shell.execute_reply":"2025-05-27T00:21:32.666646Z"}},"outputs":[{"name":"stdout","text":"--2025-05-27 00:21:31--  http://wget/\nResolving wget (wget)... failed: Name or service not known.\nwget: unable to resolve host address ‘wget’\n--2025-05-27 00:21:31--  https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/tox21.csv.gz\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 125310 (122K) [application/octet-stream]\nSaving to: ‘tox21.csv.gz’\n\ntox21.csv.gz        100%[===================>] 122.37K  --.-KB/s    in 0.01s   \n\n2025-05-27 00:21:32 (10.6 MB/s) - ‘tox21.csv.gz’ saved [125310/125310]\n\nFINISHED --2025-05-27 00:21:32--\nTotal wall clock time: 0.2s\nDownloaded: 1 files, 122K in 0.01s (10.6 MB/s)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"add_safe_globals([DataTensorAttr, DataEdgeAttr, GlobalStorage])","metadata":{"id":"D1iG2mLOokTP","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:21:32.669021Z","iopub.execute_input":"2025-05-27T00:21:32.669336Z","iopub.status.idle":"2025-05-27T00:21:32.674108Z","shell.execute_reply.started":"2025-05-27T00:21:32.669280Z","shell.execute_reply":"2025-05-27T00:21:32.673330Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Dataset","metadata":{"id":"JLWC-e33ywAM"}},{"cell_type":"code","source":"class Tox21Dataset(InMemoryDataset):\n    def __init__(self, root: str = '.', transform=None, pre_transform=None):\n        \"\"\"\n        Expects:\n        root/\n            raw/tox21.csv\n        Will create:\n            processed/data.pt\n        \"\"\"\n        super().__init__(root, transform, pre_transform)\n        # Load the processed data\n        with safe_globals([DataTensorAttr, DataEdgeAttr, GlobalStorage]):\n            self.data, self.slices = torch.load(self.processed_paths[0])\n\n    @property\n    def raw_file_names(self):\n        # File expected in root/raw/\n        return ['tox21.csv']\n\n    @property\n    def processed_file_names(self):\n        return ['data.pt']\n\n    def download(self):\n        # No download step needed; CSV is already in place\n        return\n\n    def process(self):\n        df = pd.read_csv(self.raw_paths[0])\n        df = df.fillna(value=0)\n        \n        if \"mol_id\" in df.columns:\n            df = df.drop(columns=[\"mol_id\"])\n\n        # 3) convert all non-smiles columns to numeric\n        non_smiles = [c for c in df.columns if c != \"smiles\"]\n        df[non_smiles] = df[non_smiles].apply(pd.to_numeric, errors=\"coerce\")\n        df = df.reset_index(drop=True)\n\n        data_list = []\n        bond_types = [\n            rdchem.BondType.SINGLE,\n            rdchem.BondType.DOUBLE,\n            rdchem.BondType.TRIPLE,\n            rdchem.BondType.AROMATIC,\n        ]\n        stereo_types = [\n            rdchem.BondStereo.STEREONONE,\n            rdchem.BondStereo.STEREOZ,\n            rdchem.BondStereo.STEREOE,\n            rdchem.BondStereo.STEREOANY\n        ]\n\n        for _, row in df.iterrows():\n            smiles = row[\"smiles\"]\n            mol = MolFromSmiles(smiles, sanitize=True)\n            if mol is None:\n                continue\n\n            # node features x\n            atom_feats = [\n                [\n                    a.GetAtomicNum(),\n                    a.GetDegree(),\n                    a.GetFormalCharge(),\n                    a.GetNumRadicalElectrons(),\n                    a.GetTotalNumHs(),\n                    int(a.GetIsAromatic()),\n                    int(a.IsInRing())\n                ]\n                for a in mol.GetAtoms()\n            ]\n            x = torch.tensor(atom_feats, dtype=torch.float32)\n\n            # build edge_index AND edge_attr in lock‐step\n            edge_index = []\n            edge_attr  = []\n            for bond in mol.GetBonds():\n                i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n                # one‐hot encode this bond’s type\n                bt = bond.GetBondType()\n                bfeat = [int(bt == t) for t in bond_types]\n                st = bond.GetStereo()\n                sfeat = [int(st == s) for s in stereo_types]\n                feat = bfeat + sfeat\n\n                # add both directions\n                edge_index += [[i, j], [j, i]]\n                edge_attr  += [feat, feat]\n\n            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n            edge_attr  = torch.tensor(edge_attr, dtype=torch.float32)  # [2E, len(bond_types)]\n\n            # your labels\n            y = torch.tensor(row[[c for c in df.columns if c!=\"smiles\"]].tolist(), dtype=torch.float32)\n\n            data_list.append(Data(\n                x=x,\n                edge_index=edge_index,\n                edge_attr=edge_attr,\n                y=y,\n            ))\n\n        data, slices = self.collate(data_list)\n        torch.save((data, slices), self.processed_paths[0])\n","metadata":{"id":"hVOQwpZ4yd21","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:21:34.009840Z","iopub.execute_input":"2025-05-27T00:21:34.010114Z","iopub.status.idle":"2025-05-27T00:21:34.025033Z","shell.execute_reply.started":"2025-05-27T00:21:34.010095Z","shell.execute_reply":"2025-05-27T00:21:34.024350Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"dataset = Tox21Dataset('.')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kTlchDlGFb1w","outputId":"ee3391fe-ad31-45d1-a11d-37ee5300bea3","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:21:35.744774Z","iopub.execute_input":"2025-05-27T00:21:35.745437Z","iopub.status.idle":"2025-05-27T00:21:45.770007Z","shell.execute_reply.started":"2025-05-27T00:21:35.745406Z","shell.execute_reply":"2025-05-27T00:21:45.769031Z"}},"outputs":[{"name":"stderr","text":"Processing...\n[00:21:35] WARNING: not removing hydrogen atom without neighbors\nDone!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"A **Murcko Scaffold** is a technique used to group molecules based on their core structural components. It identifies the essential building blocks by removing side chains and other non-core components, leaving behind the important ring systems and connecting chains. This method is widely used in medicinal chemistry and drug design to identify core structures that have preferential activity against specific targets, which is very useful in **molecular property prediction**.","metadata":{"id":"KjA7GOcFVrTE"}},{"cell_type":"code","source":"def GetMurckoScaffold(data, train_frac: float, val_frac: float, test_frac: float):\n    scaffold_indices = {}\n    for idx, smiles in enumerate(data):\n        scaffold_smiles = MurckoScaffold.MurckoScaffoldSmiles(smiles)\n        #scaffold_smiles = MolToSmiles(scaffold)\n        scaffold_indices.setdefault(scaffold_smiles, []).append(idx)\n\n    groups = sorted(scaffold_indices.values(), key=len, reverse=True)\n    n_total = len(data)\n    n_train = int(train_frac * n_total)\n    n_valid = int(val_frac * n_total)\n\n    train_idx, valid_idx, test_idx = [], [], []\n    for group in groups:\n        if len(train_idx) + len(group) <= n_train:\n            train_idx.extend(group)\n        elif len(valid_idx) + len(group) <= n_valid:\n            valid_idx.extend(group)\n        else:\n            test_idx.extend(group)\n\n    return train_idx, valid_idx, test_idx","metadata":{"id":"enkTOWoRzMiq","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:21:45.771472Z","iopub.execute_input":"2025-05-27T00:21:45.772103Z","iopub.status.idle":"2025-05-27T00:21:45.780252Z","shell.execute_reply.started":"2025-05-27T00:21:45.772080Z","shell.execute_reply":"2025-05-27T00:21:45.779364Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## GNN Model","metadata":{"id":"0E9B-fNYOB3q"}},{"cell_type":"code","source":"np.random.seed(1638)\ntorch.manual_seed(1638)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:21:45.781166Z","iopub.execute_input":"2025-05-27T00:21:45.781431Z","iopub.status.idle":"2025-05-27T00:21:45.809991Z","shell.execute_reply.started":"2025-05-27T00:21:45.781410Z","shell.execute_reply":"2025-05-27T00:21:45.809166Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7d2537f071d0>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"class GINEModel(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,\n        hidden_dim: int,\n        num_tasks: int,\n        n_layers: int,\n        set2set_steps: int = 3,\n    ):\n        super().__init__()\n        \n        # First GINE layer\n        self.conv1 = GINEConv(\n            nn.Sequential(\n                nn.Linear(input_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            ),\n            edge_dim=8,\n        )\n\n        # Additional GINE layers with skip connections\n        self.conv_block = nn.ModuleList()   \n        for _ in range(n_layers):\n            mlp = nn.Sequential(\n                nn.Linear(hidden_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            )\n            self.conv_block.append(GINEConv(mlp, edge_dim=8))\n\n        # Optional gated updates\n        self.gate = GatedGraphConv(hidden_dim, 3)\n        self.bn_gate = nn.BatchNorm1d(hidden_dim)\n\n        # Replace mean pool with Set2Set\n        self.pool = Set2Set(hidden_dim, processing_steps=set2set_steps)\n\n        # FC now takes 2*hidden_dim because Set2Set doubles it\n        self.fc = nn.Linear(2 * hidden_dim, num_tasks)\n\n    def forward(self, x, edge_index, edge_attr, batch):\n        # 1st GINE layer\n        x = self.conv1(x, edge_index, edge_attr)\n\n        # GINE layers + skip connections + dropout\n        for block in self.conv_block:\n            h = block(x, edge_index, edge_attr)\n            x = (x + h).relu()\n            x = F.dropout(x, p=0.1, training=self.training)\n    \n        # (Optional) gated graph conv and BN\n        x = self.gate(x, edge_index)\n        x = self.bn_gate(x)\n\n        # Set2Set pooling: output shape [batch_size, 2*hidden_dim]\n        x = self.pool(x, batch)\n\n        # Final prediction\n        return self.fc(x)","metadata":{"id":"gWhA6HDyMM5J","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:44:03.395204Z","iopub.execute_input":"2025-05-27T00:44:03.395882Z","iopub.status.idle":"2025-05-27T00:44:03.404527Z","shell.execute_reply.started":"2025-05-27T00:44:03.395851Z","shell.execute_reply":"2025-05-27T00:44:03.403713Z"}},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":"## Train the Model","metadata":{"id":"rQFEcuNXpE8C"}},{"cell_type":"code","source":"def train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        if hasattr(batch, 'edge_attr'):\n            logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n        else:\n            logits = model(batch.x, batch.edge_index, batch.batch)\n        mask = (batch.y >= 0).float()\n        bs, nt = logits.size()\n        batch_y = batch.y.view(bs, nt)\n        mask = mask.view(bs, nt)\n        loss = (criterion(logits, batch_y) * mask).sum() / mask.sum()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch.num_graphs\n    return total_loss / len(loader.dataset)","metadata":{"id":"QI3ge3gPRtHb","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:31:32.982419Z","iopub.execute_input":"2025-05-27T00:31:32.982726Z","iopub.status.idle":"2025-05-27T00:31:32.989512Z","shell.execute_reply.started":"2025-05-27T00:31:32.982706Z","shell.execute_reply":"2025-05-27T00:31:32.988753Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def evaluate(model, loader, device):\n    model.eval()\n    y, preds = [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            if hasattr(batch, 'edge_attr'):\n                logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n            else:\n                logits = model(batch.x, batch.edge_index, batch.batch)\n            y.append(batch.y.cpu())\n            preds.append(torch.sigmoid(logits).cpu())\n    return torch.cat(preds, dim=0).numpy(), torch.cat(y, dim=0).numpy()","metadata":{"id":"Ldql5-B3o-LB","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:31:33.190288Z","iopub.execute_input":"2025-05-27T00:31:33.190934Z","iopub.status.idle":"2025-05-27T00:31:33.196361Z","shell.execute_reply.started":"2025-05-27T00:31:33.190910Z","shell.execute_reply":"2025-05-27T00:31:33.195626Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## Main","metadata":{"id":"3U04GeF_qONW"}},{"cell_type":"code","source":"df = pd.read_csv('raw/tox21.csv').fillna(0).reset_index(drop=True)\nsmiles_list = df['smiles'].tolist()\ntrain_idx, valid_idx, test_idx = GetMurckoScaffold(smiles_list, 0.8, 0.1, 0.1)\n\ntrain_ds = Subset(dataset, train_idx)\nval_ds   = Subset(dataset, valid_idx)\ntest_ds  = Subset(dataset, test_idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)#, sampler=sampler)\nval_loader   = DataLoader(val_ds,   batch_size=32, shuffle=True)\ntest_loader  = DataLoader(test_ds,  batch_size=32)\n\nsample = dataset[0]\nin_channels = sample.x.size(1)\nnum_tasks   = sample.y.size(0)\n\nprint(\"There are\", num_tasks, \"tasks.\")","metadata":{"id":"Xawk2eEFs2Sm","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:31:33.884699Z","iopub.execute_input":"2025-05-27T00:31:33.885504Z","iopub.status.idle":"2025-05-27T00:31:36.560741Z","shell.execute_reply.started":"2025-05-27T00:31:33.885468Z","shell.execute_reply":"2025-05-27T00:31:36.559990Z"}},"outputs":[{"name":"stderr","text":"[00:31:33] WARNING: not removing hydrogen atom without neighbors\n","output_type":"stream"},{"name":"stdout","text":"There are 12 tasks.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GINEModel(\n    in_channels,\n    hidden_dim = 384,\n    num_tasks = num_tasks,\n    #dropout = 0.2,\n    n_layers = 3\n).to(device)\n\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:44:08.519887Z","iopub.execute_input":"2025-05-27T00:44:08.520673Z","iopub.status.idle":"2025-05-27T00:44:08.597855Z","shell.execute_reply.started":"2025-05-27T00:44:08.520647Z","shell.execute_reply":"2025-05-27T00:44:08.596972Z"}},"outputs":[{"name":"stdout","text":"GINEModel(\n  (conv1): GINEConv(nn=Sequential(\n    (0): Linear(in_features=7, out_features=384, bias=True)\n    (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Linear(in_features=384, out_features=384, bias=True)\n  ))\n  (conv_block): ModuleList(\n    (0-2): 3 x GINEConv(nn=Sequential(\n      (0): Linear(in_features=384, out_features=384, bias=True)\n      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=384, out_features=384, bias=True)\n    ))\n  )\n  (gate): GatedGraphConv(384, num_layers=3)\n  (bn_gate): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool): Set2Set(384, 768)\n  (fc): Linear(in_features=768, out_features=12, bias=True)\n)\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"optimizer = optim.AdamW(\n    model.parameters(),\n    lr=1e-4,\n    weight_decay=1e-5,\n)\n\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode=\"max\",           # we track val AUC, so “max”\n    factor=0.5,           # halve the lr\n    patience=5,           # after 5 epochs with no AUC gain\n    min_lr=1e-6\n)","metadata":{"id":"KjGvP1-jwVFM","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:44:10.003911Z","iopub.execute_input":"2025-05-27T00:44:10.004527Z","iopub.status.idle":"2025-05-27T00:44:10.009585Z","shell.execute_reply.started":"2025-05-27T00:44:10.004493Z","shell.execute_reply":"2025-05-27T00:44:10.008709Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, logits, targets):\n        # logits: shape [N, ...], raw outputs\n        # targets: same shape, 0 or 1\n        probas = torch.sigmoid(logits)\n        # p_t: prob of true class\n        p_t = probas * targets + (1 - probas) * (1 - targets)\n        # alpha factor\n        alpha_factor = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n        # focal weight\n        focal_weight = alpha_factor * (1 - p_t) ** self.gamma\n        # binary cross‐entropy per example\n        bce = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n        loss = focal_weight * bce\n\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        else:\n            return loss\n\ncriterion = FocalLoss(alpha=0.10, gamma=1.0, reduction='none')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:44:10.616832Z","iopub.execute_input":"2025-05-27T00:44:10.617359Z","iopub.status.idle":"2025-05-27T00:44:10.624186Z","shell.execute_reply.started":"2025-05-27T00:44:10.617328Z","shell.execute_reply":"2025-05-27T00:44:10.623418Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"for epoch in range(1, 21):\n    loss = train_epoch(model, train_loader, optimizer, criterion, device)\n    ps_val, ys_val = evaluate(model, val_loader, device)\n    ys_val = ys_val.reshape(ps_val.shape)\n    aucs = []\n    for i in range(ps_val.shape[1]):\n        mask = ys_val[:, i] >= 0\n        if mask.sum() > 0:\n            aucs.append(roc_auc_score(ys_val[mask, i], ps_val[mask, i]))\n    scheduler.step(np.mean(aucs)) # we use the mean like below\n    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Val AUC: {np.mean(aucs):.3f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"gp_XvcMsw8jW","outputId":"0af71082-b925-49a3-edc8-f8c8569144f3","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:44:12.305848Z","iopub.execute_input":"2025-05-27T00:44:12.306147Z","iopub.status.idle":"2025-05-27T00:45:39.822666Z","shell.execute_reply.started":"2025-05-27T00:44:12.306124Z","shell.execute_reply":"2025-05-27T00:45:39.821761Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Loss: 0.0377 | Val AUC: 0.592\nEpoch 02 | Loss: 0.0185 | Val AUC: 0.595\nEpoch 03 | Loss: 0.0178 | Val AUC: 0.621\nEpoch 04 | Loss: 0.0176 | Val AUC: 0.660\nEpoch 05 | Loss: 0.0171 | Val AUC: 0.667\nEpoch 06 | Loss: 0.0170 | Val AUC: 0.664\nEpoch 07 | Loss: 0.0170 | Val AUC: 0.645\nEpoch 08 | Loss: 0.0170 | Val AUC: 0.666\nEpoch 09 | Loss: 0.0166 | Val AUC: 0.687\nEpoch 10 | Loss: 0.0164 | Val AUC: 0.684\nEpoch 11 | Loss: 0.0163 | Val AUC: 0.697\nEpoch 12 | Loss: 0.0159 | Val AUC: 0.700\nEpoch 13 | Loss: 0.0158 | Val AUC: 0.696\nEpoch 14 | Loss: 0.0159 | Val AUC: 0.648\nEpoch 15 | Loss: 0.0162 | Val AUC: 0.715\nEpoch 16 | Loss: 0.0159 | Val AUC: 0.698\nEpoch 17 | Loss: 0.0156 | Val AUC: 0.705\nEpoch 18 | Loss: 0.0154 | Val AUC: 0.700\nEpoch 19 | Loss: 0.0154 | Val AUC: 0.689\nEpoch 20 | Loss: 0.0154 | Val AUC: 0.697\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"ps_test, ys_test = evaluate(model, test_loader, device)\nys_test = ys_test.reshape(ps_test.shape)\naucs = []\nfor i in range(ps_test.shape[1]):\n    mask = ys_test[:, i] >= 0\n    if mask.sum() > 0:\n        aucs.append(roc_auc_score(ys_test[mask, i], ps_test[mask, i]))\nprint(f\"Testing | Loss: {loss:.4f} | Test AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:45:39.824080Z","iopub.execute_input":"2025-05-27T00:45:39.824379Z","iopub.status.idle":"2025-05-27T00:45:40.081392Z","shell.execute_reply.started":"2025-05-27T00:45:39.824354Z","shell.execute_reply":"2025-05-27T00:45:40.080569Z"}},"outputs":[{"name":"stdout","text":"Testing | Loss: 0.0154 | Test AUC: 0.699\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"### GINE with Jumping Knowledge Model","metadata":{}},{"cell_type":"code","source":"class GINEWithJK(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,\n        hidden_dim: int,\n        num_tasks: int,\n        n_layers: int,\n        jk_mode: str = 'cat', \n        set2set_steps: int = 3,\n    ):\n        super().__init__()\n        self.n_layers = n_layers\n\n        # first GINE\n        self.conv1 = GINEConv(\n            nn.Sequential(\n                nn.Linear(input_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            ),\n            edge_dim=8,\n        )\n\n        # additional GINE layers\n        self.convs = nn.ModuleList()\n        for _ in range(n_layers):\n            mlp = nn.Sequential(\n                nn.Linear(hidden_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            )\n            self.convs.append(GINEConv(mlp, edge_dim=8))\n\n        # Jumping Knowledge combiner\n        # if mode='cat', output size = hidden_dim*(n_layers+1)\n        self.jk = JumpingKnowledge(mode=jk_mode)\n\n        # pooling: either Set2Set or mean\n        # If using Set2Set, pool_in_dim = hidden_dim*(n_layers+1)\n        self.pool = Set2Set(hidden_dim * (n_layers + 1), processing_steps=set2set_steps)\n        # otherwise: self.pool = global_mean_pool\n\n        # final FC — input dim doubles due to Set2Set concat\n        self.fc = nn.Linear(2 * hidden_dim * (n_layers + 1), num_tasks)\n\n    def forward(self, x, edge_index, edge_attr, batch):\n        xs = []\n        # layer 0\n        x = F.relu(self.conv1(x, edge_index, edge_attr))\n        xs.append(x)\n\n        # layers 1…n\n        for conv in self.convs:\n            x = F.relu(conv(x, edge_index, edge_attr))\n            xs.append(x)\n\n        # combine via JK\n        x = self.jk(xs)   # if 'cat', shape = [total_nodes, hidden_dim*(n_layers+1)]\n\n        # pooling\n        x = self.pool(x, batch)  # -> [batch_size, 2*hidden_dim*(n_layers+1)]\n\n        # final prediction\n        return self.fc(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:45:59.527175Z","iopub.execute_input":"2025-05-27T00:45:59.527493Z","iopub.status.idle":"2025-05-27T00:45:59.536867Z","shell.execute_reply.started":"2025-05-27T00:45:59.527472Z","shell.execute_reply":"2025-05-27T00:45:59.535677Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"jk_model = GINEWithJK(\n    in_channels,\n    hidden_dim = 384,\n    num_tasks = num_tasks,\n    n_layers = 3,\n    jk_mode = 'cat',\n    set2set_steps = 3,\n).to(device)\n\nprint(jk_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:46:59.368719Z","iopub.execute_input":"2025-05-27T00:46:59.368998Z","iopub.status.idle":"2025-05-27T00:46:59.881011Z","shell.execute_reply.started":"2025-05-27T00:46:59.368978Z","shell.execute_reply":"2025-05-27T00:46:59.880104Z"}},"outputs":[{"name":"stdout","text":"GINEWithJK(\n  (conv1): GINEConv(nn=Sequential(\n    (0): Linear(in_features=7, out_features=384, bias=True)\n    (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Linear(in_features=384, out_features=384, bias=True)\n  ))\n  (convs): ModuleList(\n    (0-2): 3 x GINEConv(nn=Sequential(\n      (0): Linear(in_features=384, out_features=384, bias=True)\n      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=384, out_features=384, bias=True)\n    ))\n  )\n  (jk): JumpingKnowledge(cat)\n  (pool): Set2Set(1536, 3072)\n  (fc): Linear(in_features=3072, out_features=12, bias=True)\n)\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"jk_optimizer = optim.AdamW(\n    jk_model.parameters(),\n    lr=1e-4,\n    weight_decay=1e-5,\n)\n\njk_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    jk_optimizer,\n    mode=\"max\",           # we track val AUC, so “max”\n    factor=0.5,           # halve the lr\n    patience=5,           # after 5 epochs with no AUC gain\n    min_lr=1e-6\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:47:37.923693Z","iopub.execute_input":"2025-05-27T00:47:37.923997Z","iopub.status.idle":"2025-05-27T00:47:37.929105Z","shell.execute_reply.started":"2025-05-27T00:47:37.923974Z","shell.execute_reply":"2025-05-27T00:47:37.928366Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"jk_criterion = FocalLoss(alpha=0.2, gamma=1.4, reduction='none')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:48:09.359945Z","iopub.execute_input":"2025-05-27T00:48:09.360239Z","iopub.status.idle":"2025-05-27T00:48:09.364387Z","shell.execute_reply.started":"2025-05-27T00:48:09.360217Z","shell.execute_reply":"2025-05-27T00:48:09.363500Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"for epoch in range(1, 21):\n    loss = train_epoch(jk_model, train_loader, jk_optimizer, jk_criterion, device)\n    ps_val, ys_val = evaluate(jk_model, val_loader, device)\n    ys_val = ys_val.reshape(ps_val.shape)\n    aucs = []\n    for i in range(ps_val.shape[1]):\n        mask = ys_val[:, i] >= 0\n        if mask.sum() > 0:\n            aucs.append(roc_auc_score(ys_val[mask, i], ps_val[mask, i]))\n    jk_scheduler.step(np.mean(aucs)) # we use the mean like below\n    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Val AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:48:31.119199Z","iopub.execute_input":"2025-05-27T00:48:31.119523Z","iopub.status.idle":"2025-05-27T00:50:42.879732Z","shell.execute_reply.started":"2025-05-27T00:48:31.119490Z","shell.execute_reply":"2025-05-27T00:50:42.879017Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Loss: 0.0286 | Val AUC: 0.682\nEpoch 02 | Loss: 0.0227 | Val AUC: 0.702\nEpoch 03 | Loss: 0.0220 | Val AUC: 0.694\nEpoch 04 | Loss: 0.0216 | Val AUC: 0.726\nEpoch 05 | Loss: 0.0211 | Val AUC: 0.710\nEpoch 06 | Loss: 0.0207 | Val AUC: 0.721\nEpoch 07 | Loss: 0.0204 | Val AUC: 0.727\nEpoch 08 | Loss: 0.0201 | Val AUC: 0.707\nEpoch 09 | Loss: 0.0198 | Val AUC: 0.720\nEpoch 10 | Loss: 0.0196 | Val AUC: 0.731\nEpoch 11 | Loss: 0.0194 | Val AUC: 0.722\nEpoch 12 | Loss: 0.0190 | Val AUC: 0.721\nEpoch 13 | Loss: 0.0187 | Val AUC: 0.733\nEpoch 14 | Loss: 0.0186 | Val AUC: 0.719\nEpoch 15 | Loss: 0.0183 | Val AUC: 0.738\nEpoch 16 | Loss: 0.0179 | Val AUC: 0.717\nEpoch 17 | Loss: 0.0177 | Val AUC: 0.717\nEpoch 18 | Loss: 0.0174 | Val AUC: 0.721\nEpoch 19 | Loss: 0.0173 | Val AUC: 0.720\nEpoch 20 | Loss: 0.0170 | Val AUC: 0.724\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"ps_test, ys_test = evaluate(jk_model, test_loader, device)\nys_test = ys_test.reshape(ps_test.shape)\naucs = []\nfor i in range(ps_test.shape[1]):\n    mask = ys_test[:, i] >= 0\n    if mask.sum() > 0:\n        aucs.append(roc_auc_score(ys_test[mask, i], ps_test[mask, i]))\nprint(f\"Testing | Loss: {loss:.4f} | Test AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T00:55:19.405899Z","iopub.execute_input":"2025-05-27T00:55:19.406839Z","iopub.status.idle":"2025-05-27T00:55:19.691903Z","shell.execute_reply.started":"2025-05-27T00:55:19.406806Z","shell.execute_reply":"2025-05-27T00:55:19.691179Z"}},"outputs":[{"name":"stdout","text":"Testing | Loss: 0.0170 | Test AUC: 0.714\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}