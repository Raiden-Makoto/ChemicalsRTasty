{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["VC6dgzIvNpYm","JLWC-e33ywAM","0E9B-fNYOB3q","rQFEcuNXpE8C"],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tox21 GINENet\n\nWe’re solving a multi-task binary toxicity prediction problem on Tox21. Concretely, for each molecule the model outputs 12 probabilities, one for each assay (e.g. NR-AR, SR-ARE, p53, etc.). At training time we use a binary cross-entropy loss (with masking for missing labels) over those 12 tasks, and at the end of each epoch we compute the ROC-AUC per task (then average) on the held-out validation set to see how well the model is distinguishing actives vs. inactives across all assays.","metadata":{"id":"VC6dgzIvNpYm"}},{"cell_type":"code","source":"%pip -q install rdkit-pypi torch_geometric","metadata":{"id":"l0Z81NMxoiW9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e17f73e4-4830-4b56-b3bc-34550217458f","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:08:35.404401Z","iopub.execute_input":"2025-05-26T03:08:35.404882Z","iopub.status.idle":"2025-05-26T03:08:41.989258Z","shell.execute_reply.started":"2025-05-26T03:08:35.404856Z","shell.execute_reply":"2025-05-26T03:08:41.988540Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Subset, WeightedRandomSampler\nfrom torch.serialization import safe_globals, add_safe_globals\n\n# Pytorch Geometric Imports\nfrom torch_geometric.data import InMemoryDataset, Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.data.data import DataTensorAttr, DataEdgeAttr\nfrom torch_geometric.data.storage import GlobalStorage\nfrom torch_geometric.nn import GINEConv, GatedGraphConv, Set2Set, global_mean_pool\n\n# RDKit Imports\nfrom rdkit.Chem.Scaffolds import MurckoScaffold\nfrom rdkit.Chem import MolFromSmiles, MolToSmiles, rdchem\n\nfrom sklearn.metrics import roc_auc_score\nimport os","metadata":{"id":"TmEESHMxt72N","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:11:05.782719Z","iopub.execute_input":"2025-05-26T03:11:05.783359Z","iopub.status.idle":"2025-05-26T03:11:05.788278Z","shell.execute_reply.started":"2025-05-26T03:11:05.783337Z","shell.execute_reply":"2025-05-26T03:11:05.787664Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"!wget wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/tox21.csv.gz\n!gunzip tox21.csv.gz\n!mkdir -p raw\n!mv tox21.csv raw/","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4dsjviCYyJpu","outputId":"1df76760-1456-4190-c35e-e668485b0878","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:09:02.930936Z","iopub.execute_input":"2025-05-26T03:09:02.931647Z","iopub.status.idle":"2025-05-26T03:09:03.689611Z","shell.execute_reply.started":"2025-05-26T03:09:02.931624Z","shell.execute_reply":"2025-05-26T03:09:03.688469Z"}},"outputs":[{"name":"stdout","text":"--2025-05-26 03:09:02--  http://wget/\nResolving wget (wget)... failed: Name or service not known.\nwget: unable to resolve host address ‘wget’\n--2025-05-26 03:09:02--  https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/tox21.csv.gz\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 125310 (122K) [application/octet-stream]\nSaving to: ‘tox21.csv.gz’\n\ntox21.csv.gz        100%[===================>] 122.37K  --.-KB/s    in 0.02s   \n\n2025-05-26 03:09:03 (5.53 MB/s) - ‘tox21.csv.gz’ saved [125310/125310]\n\nFINISHED --2025-05-26 03:09:03--\nTotal wall clock time: 0.2s\nDownloaded: 1 files, 122K in 0.02s (5.53 MB/s)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"add_safe_globals([DataTensorAttr, DataEdgeAttr, GlobalStorage])","metadata":{"id":"D1iG2mLOokTP","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:09:05.180672Z","iopub.execute_input":"2025-05-26T03:09:05.181307Z","iopub.status.idle":"2025-05-26T03:09:05.185369Z","shell.execute_reply.started":"2025-05-26T03:09:05.181275Z","shell.execute_reply":"2025-05-26T03:09:05.184549Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Dataset","metadata":{"id":"JLWC-e33ywAM"}},{"cell_type":"code","source":"class Tox21Dataset(InMemoryDataset):\n    def __init__(self, root: str = '.', transform=None, pre_transform=None):\n        \"\"\"\n        Expects:\n        root/\n            raw/tox21.csv\n        Will create:\n            processed/data.pt\n        \"\"\"\n        super().__init__(root, transform, pre_transform)\n        # Load the processed data\n        with safe_globals([DataTensorAttr, DataEdgeAttr, GlobalStorage]):\n            self.data, self.slices = torch.load(self.processed_paths[0])\n\n    @property\n    def raw_file_names(self):\n        # File expected in root/raw/\n        return ['tox21.csv']\n\n    @property\n    def processed_file_names(self):\n        return ['data.pt']\n\n    def download(self):\n        # No download step needed; CSV is already in place\n        return\n\n    def process(self):\n        df = pd.read_csv(self.raw_paths[0])\n        df = df.fillna(value=0)\n        \n        if \"mol_id\" in df.columns:\n            df = df.drop(columns=[\"mol_id\"])\n\n        # 3) convert all non-smiles columns to numeric\n        non_smiles = [c for c in df.columns if c != \"smiles\"]\n        df[non_smiles] = df[non_smiles].apply(pd.to_numeric, errors=\"coerce\")\n        df = df.reset_index(drop=True)\n\n        data_list = []\n        bond_types = [\n            rdchem.BondType.SINGLE,\n            rdchem.BondType.DOUBLE,\n            rdchem.BondType.TRIPLE,\n            rdchem.BondType.AROMATIC,\n        ]\n        stereo_types = [\n            rdchem.BondStereo.STEREONONE,\n            rdchem.BondStereo.STEREOZ,\n            rdchem.BondStereo.STEREOE,\n            rdchem.BondStereo.STEREOANY\n        ]\n\n        for _, row in df.iterrows():\n            smiles = row[\"smiles\"]\n            mol    = MolFromSmiles(smiles, sanitize=True)\n            if mol is None:\n                continue\n\n            # node features x\n            atom_feats = [\n                [\n                    a.GetAtomicNum(),\n                    a.GetDegree(),\n                    a.GetFormalCharge(),\n                    a.GetNumRadicalElectrons(),\n                    a.GetTotalNumHs(),\n                    int(a.GetIsAromatic()),\n                    int(a.IsInRing())\n                ]\n                for a in mol.GetAtoms()\n            ]\n            x = torch.tensor(atom_feats, dtype=torch.float32)\n\n            # build edge_index AND edge_attr in lock‐step\n            edge_index = []\n            edge_attr  = []\n            for bond in mol.GetBonds():\n                i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n                # one‐hot encode this bond’s type\n                bt = bond.GetBondType()\n                bfeat = [int(bt == t) for t in bond_types]\n                st = bond.GetStereo()\n                sfeat = [int(st == s) for s in stereo_types]\n                feat = bfeat + sfeat\n\n                # add both directions\n                edge_index += [[i, j], [j, i]]\n                edge_attr  += [feat, feat]\n\n            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n            edge_attr  = torch.tensor(edge_attr, dtype=torch.float32)  # [2E, len(bond_types)]\n\n            # your labels\n            y = torch.tensor(row[[c for c in df.columns if c!=\"smiles\"]]\n                             .tolist(), dtype=torch.float32)\n\n            data_list.append(Data(\n                x=x,\n                edge_index=edge_index,\n                edge_attr=edge_attr,\n                y=y,\n            ))\n\n        data, slices = self.collate(data_list)\n        torch.save((data, slices), self.processed_paths[0])\n","metadata":{"id":"hVOQwpZ4yd21","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:09:07.408280Z","iopub.execute_input":"2025-05-26T03:09:07.408823Z","iopub.status.idle":"2025-05-26T03:09:07.421745Z","shell.execute_reply.started":"2025-05-26T03:09:07.408798Z","shell.execute_reply":"2025-05-26T03:09:07.421033Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dataset = Tox21Dataset('.')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kTlchDlGFb1w","outputId":"ee3391fe-ad31-45d1-a11d-37ee5300bea3","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:09:17.852838Z","iopub.execute_input":"2025-05-26T03:09:17.853341Z","iopub.status.idle":"2025-05-26T03:09:26.298509Z","shell.execute_reply.started":"2025-05-26T03:09:17.853316Z","shell.execute_reply":"2025-05-26T03:09:26.297802Z"}},"outputs":[{"name":"stderr","text":"Processing...\n[03:09:18] WARNING: not removing hydrogen atom without neighbors\nDone!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"A **Murcko Scaffold** is a technique used to group molecules based on their core structural components. It identifies the essential building blocks by removing side chains and other non-core components, leaving behind the important ring systems and connecting chains. This method is widely used in medicinal chemistry and drug design to identify core structures that have preferential activity against specific targets, which is very useful in **molecular property prediction**.","metadata":{"id":"KjA7GOcFVrTE"}},{"cell_type":"code","source":"def GetMurckoScaffold(data, train_frac: float, val_frac: float, test_frac: float):\n    scaffold_indices = {}\n    for idx, smiles in enumerate(data):\n        scaffold_smiles = MurckoScaffold.MurckoScaffoldSmiles(smiles)\n        #scaffold_smiles = MolToSmiles(scaffold)\n        scaffold_indices.setdefault(scaffold_smiles, []).append(idx)\n\n    groups = sorted(scaffold_indices.values(), key=len, reverse=True)\n    n_total = len(data)\n    n_train = int(train_frac * n_total)\n    n_valid = int(val_frac * n_total)\n\n    train_idx, valid_idx, test_idx = [], [], []\n    for group in groups:\n        if len(train_idx) + len(group) <= n_train:\n            train_idx.extend(group)\n        elif len(valid_idx) + len(group) <= n_valid:\n            valid_idx.extend(group)\n        else:\n            test_idx.extend(group)\n\n    return train_idx, valid_idx, test_idx","metadata":{"id":"enkTOWoRzMiq","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:09:26.299555Z","iopub.execute_input":"2025-05-26T03:09:26.299779Z","iopub.status.idle":"2025-05-26T03:09:26.307136Z","shell.execute_reply.started":"2025-05-26T03:09:26.299760Z","shell.execute_reply":"2025-05-26T03:09:26.306396Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## GNN Model","metadata":{"id":"0E9B-fNYOB3q"}},{"cell_type":"code","source":"np.random.seed(1638)\ntorch.manual_seed(1638)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:09:26.888841Z","iopub.execute_input":"2025-05-26T03:09:26.889548Z","iopub.status.idle":"2025-05-26T03:09:26.899786Z","shell.execute_reply.started":"2025-05-26T03:09:26.889524Z","shell.execute_reply":"2025-05-26T03:09:26.899100Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7c0a401db1d0>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"class GINEModel(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,\n        hidden_dim: int,\n        num_tasks: int,\n        n_layers: int,\n        set2set_steps: int = 3,\n    ):\n        super().__init__()\n        \n        # First GINE layer\n        self.conv1 = GINEConv(\n            nn.Sequential(\n                nn.Linear(input_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            ),\n            edge_dim=8,\n        )\n\n        # Additional GINE layers with skip connections\n        self.conv_block = nn.ModuleList()   \n        for _ in range(n_layers):\n            mlp = nn.Sequential(\n                nn.Linear(hidden_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            )\n            self.conv_block.append(GINEConv(mlp, edge_dim=8))\n\n        # Optional gated updates\n        self.gate = GatedGraphConv(hidden_dim, 3)\n        self.bn_gate = nn.BatchNorm1d(hidden_dim)\n\n        # Replace mean pool with Set2Set\n        self.pool = Set2Set(hidden_dim, processing_steps=set2set_steps)\n\n        # FC now takes 2*hidden_dim because Set2Set doubles it\n        self.fc = nn.Linear(2 * hidden_dim, num_tasks)\n\n    def forward(self, x, edge_index, edge_attr, batch):\n        # 1st GINE layer\n        x = self.conv1(x, edge_index, edge_attr)\n\n        # GINE layers + skip connections + dropout\n        for block in self.conv_block:\n            h = block(x, edge_index, edge_attr)\n            x = (x + h).relu()\n            x = F.dropout(x, p=0.1, training=self.training)\n    \n        # (Optional) gated graph conv and BN\n        x = self.gate(x, edge_index)\n        x = self.bn_gate(x)\n\n        # Set2Set pooling: output shape [batch_size, 2*hidden_dim]\n        x = self.pool(x, batch)\n\n        # Final prediction\n        return self.fc(x)\n","metadata":{"id":"gWhA6HDyMM5J","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:09:55.840783Z","iopub.execute_input":"2025-05-26T03:09:55.841559Z","iopub.status.idle":"2025-05-26T03:09:55.849635Z","shell.execute_reply.started":"2025-05-26T03:09:55.841534Z","shell.execute_reply":"2025-05-26T03:09:55.848719Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Train the Model","metadata":{"id":"rQFEcuNXpE8C"}},{"cell_type":"code","source":"def train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        if hasattr(batch, 'edge_attr'):\n            logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n        else:\n            logits = model(batch.x, batch.edge_index, batch.batch)\n        mask = (batch.y >= 0).float()\n        bs, nt = logits.size()\n        batch_y = batch.y.view(bs, nt)\n        mask = mask.view(bs, nt)\n        loss = (criterion(logits, batch_y) * mask).sum() / mask.sum()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch.num_graphs\n    return total_loss / len(loader.dataset)","metadata":{"id":"QI3ge3gPRtHb","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:09:56.903993Z","iopub.execute_input":"2025-05-26T03:09:56.904262Z","iopub.status.idle":"2025-05-26T03:09:56.910097Z","shell.execute_reply.started":"2025-05-26T03:09:56.904241Z","shell.execute_reply":"2025-05-26T03:09:56.909294Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def evaluate(model, loader, device):\n    model.eval()\n    y, preds = [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            if hasattr(batch, 'edge_attr'):\n                logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n            else:\n                logits = model(batch.x, batch.edge_index, batch.batch)\n            y.append(batch.y.cpu())\n            preds.append(torch.sigmoid(logits).cpu())\n    return torch.cat(preds, dim=0).numpy(), torch.cat(y, dim=0).numpy()","metadata":{"id":"Ldql5-B3o-LB","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:09:58.440887Z","iopub.execute_input":"2025-05-26T03:09:58.441439Z","iopub.status.idle":"2025-05-26T03:09:58.446597Z","shell.execute_reply.started":"2025-05-26T03:09:58.441415Z","shell.execute_reply":"2025-05-26T03:09:58.445681Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Main","metadata":{"id":"3U04GeF_qONW"}},{"cell_type":"code","source":"df = pd.read_csv('raw/tox21.csv').fillna(0).reset_index(drop=True)\nsmiles_list = df['smiles'].tolist()\ntrain_idx, valid_idx, test_idx = GetMurckoScaffold(smiles_list, 0.8, 0.1, 0.1)\n\ntrain_ds = Subset(dataset, train_idx)\nval_ds   = Subset(dataset, valid_idx)\ntest_ds  = Subset(dataset, test_idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)#, sampler=sampler)\nval_loader   = DataLoader(val_ds,   batch_size=32, shuffle=True)\ntest_loader  = DataLoader(test_ds,  batch_size=32)\n\nsample = dataset[0]\nin_channels = sample.x.size(1)\nnum_tasks   = sample.y.size(0)\n\nprint(\"There are\", num_tasks, \"tasks.\")","metadata":{"id":"Xawk2eEFs2Sm","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:10:00.594136Z","iopub.execute_input":"2025-05-26T03:10:00.594492Z","iopub.status.idle":"2025-05-26T03:10:02.733624Z","shell.execute_reply.started":"2025-05-26T03:10:00.594470Z","shell.execute_reply":"2025-05-26T03:10:02.732894Z"}},"outputs":[{"name":"stderr","text":"[03:10:00] WARNING: not removing hydrogen atom without neighbors\n","output_type":"stream"},{"name":"stdout","text":"There are 12 tasks.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"df.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:10:02.734574Z","iopub.execute_input":"2025-05-26T03:10:02.734809Z","iopub.status.idle":"2025-05-26T03:10:02.759231Z","shell.execute_reply.started":"2025-05-26T03:10:02.734793Z","shell.execute_reply":"2025-05-26T03:10:02.758361Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"      NR-AR  NR-AR-LBD  NR-AhR  NR-Aromatase  NR-ER  NR-ER-LBD  NR-PPAR-gamma  \\\n8009    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n8010    1.0        1.0     0.0           0.0    1.0        0.0            0.0   \n8011    1.0        1.0     0.0           0.0    1.0        1.0            0.0   \n8012    1.0        1.0     0.0           0.0    1.0        1.0            0.0   \n8013    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n\n      SR-ARE  SR-ATAD5  SR-HSE  SR-MMP  SR-p53   mol_id  \\\n8009     0.0       0.0     0.0     0.0     0.0  TOX2725   \n8010     0.0       0.0     0.0     0.0     0.0  TOX2370   \n8011     1.0       0.0     0.0     0.0     0.0  TOX2371   \n8012     0.0       0.0     0.0     1.0     1.0  TOX2377   \n8013     0.0       0.0     0.0     1.0     0.0  TOX2724   \n\n                                                 smiles  \n8009  CCOc1nc2cccc(C(=O)O)c2n1Cc1ccc(-c2ccccc2-c2nnn...  \n8010  CC(=O)[C@H]1CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(...  \n8011  C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)CC[C@@]43C)[C...  \n8012  C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...  \n8013            COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NR-AR</th>\n      <th>NR-AR-LBD</th>\n      <th>NR-AhR</th>\n      <th>NR-Aromatase</th>\n      <th>NR-ER</th>\n      <th>NR-ER-LBD</th>\n      <th>NR-PPAR-gamma</th>\n      <th>SR-ARE</th>\n      <th>SR-ATAD5</th>\n      <th>SR-HSE</th>\n      <th>SR-MMP</th>\n      <th>SR-p53</th>\n      <th>mol_id</th>\n      <th>smiles</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8009</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>TOX2725</td>\n      <td>CCOc1nc2cccc(C(=O)O)c2n1Cc1ccc(-c2ccccc2-c2nnn...</td>\n    </tr>\n    <tr>\n      <th>8010</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>TOX2370</td>\n      <td>CC(=O)[C@H]1CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(...</td>\n    </tr>\n    <tr>\n      <th>8011</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>TOX2371</td>\n      <td>C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)CC[C@@]43C)[C...</td>\n    </tr>\n    <tr>\n      <th>8012</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>TOX2377</td>\n      <td>C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...</td>\n    </tr>\n    <tr>\n      <th>8013</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>TOX2724</td>\n      <td>COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GINEModel(\n    in_channels,\n    hidden_dim = 384,\n    num_tasks = num_tasks,\n    #dropout = 0.2,\n    n_layers = 3\n).to(device)\n\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:10:02.760201Z","iopub.execute_input":"2025-05-26T03:10:02.760456Z","iopub.status.idle":"2025-05-26T03:10:03.129696Z","shell.execute_reply.started":"2025-05-26T03:10:02.760438Z","shell.execute_reply":"2025-05-26T03:10:03.129078Z"}},"outputs":[{"name":"stdout","text":"GINEModel(\n  (conv1): GINEConv(nn=Sequential(\n    (0): Linear(in_features=7, out_features=384, bias=True)\n    (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Linear(in_features=384, out_features=384, bias=True)\n  ))\n  (conv_block): ModuleList(\n    (0-2): 3 x GINEConv(nn=Sequential(\n      (0): Linear(in_features=384, out_features=384, bias=True)\n      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=384, out_features=384, bias=True)\n    ))\n  )\n  (gate): GatedGraphConv(384, num_layers=3)\n  (bn_gate): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool): Set2Set(384, 768)\n  (fc): Linear(in_features=768, out_features=12, bias=True)\n)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"optimizer = optim.AdamW(\n    model.parameters(),\n    lr=1e-4,\n    weight_decay=1e-5,\n)\n\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode=\"max\",           # we track val AUC, so “max”\n    factor=0.5,           # halve the lr\n    patience=5,           # after 5 epochs with no AUC gain\n    min_lr=1e-6\n)\n\ncriterion = nn.BCEWithLogitsLoss(reduction='none')","metadata":{"id":"KjGvP1-jwVFM","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:10:46.005168Z","iopub.execute_input":"2025-05-26T03:10:46.005687Z","iopub.status.idle":"2025-05-26T03:10:46.010325Z","shell.execute_reply.started":"2025-05-26T03:10:46.005663Z","shell.execute_reply":"2025-05-26T03:10:46.009602Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"for epoch in range(1, 21):\n    loss = train_epoch(model, train_loader, optimizer, criterion, device)\n    ps_val, ys_val = evaluate(model, val_loader, device)\n    ys_val = ys_val.reshape(ps_val.shape)\n    aucs = []\n    for i in range(ps_val.shape[1]):\n        mask = ys_val[:, i] >= 0\n        if mask.sum() > 0:\n            aucs.append(roc_auc_score(ys_val[mask, i], ps_val[mask, i]))\n    scheduler.step(np.mean(aucs)) # we use the mean like below\n    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Val AUC: {np.mean(aucs):.3f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"gp_XvcMsw8jW","outputId":"0af71082-b925-49a3-edc8-f8c8569144f3","trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:11:12.647112Z","iopub.execute_input":"2025-05-26T03:11:12.647808Z","iopub.status.idle":"2025-05-26T03:12:26.081882Z","shell.execute_reply.started":"2025-05-26T03:11:12.647775Z","shell.execute_reply":"2025-05-26T03:12:26.081089Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Loss: 0.2537 | Val AUC: 0.605\nEpoch 02 | Loss: 0.2083 | Val AUC: 0.646\nEpoch 03 | Loss: 0.2001 | Val AUC: 0.666\nEpoch 04 | Loss: 0.1918 | Val AUC: 0.676\nEpoch 05 | Loss: 0.1874 | Val AUC: 0.683\nEpoch 06 | Loss: 0.1859 | Val AUC: 0.667\nEpoch 07 | Loss: 0.1965 | Val AUC: 0.672\nEpoch 08 | Loss: 0.1890 | Val AUC: 0.689\nEpoch 09 | Loss: 0.1885 | Val AUC: 0.671\nEpoch 10 | Loss: 0.1881 | Val AUC: 0.694\nEpoch 11 | Loss: 0.1798 | Val AUC: 0.687\nEpoch 12 | Loss: 0.1787 | Val AUC: 0.704\nEpoch 13 | Loss: 0.1774 | Val AUC: 0.703\nEpoch 14 | Loss: 0.1751 | Val AUC: 0.713\nEpoch 15 | Loss: 0.1730 | Val AUC: 0.702\nEpoch 16 | Loss: 0.1715 | Val AUC: 0.722\nEpoch 17 | Loss: 0.1703 | Val AUC: 0.711\nEpoch 18 | Loss: 0.1697 | Val AUC: 0.719\nEpoch 19 | Loss: 0.1690 | Val AUC: 0.719\nEpoch 20 | Loss: 0.1660 | Val AUC: 0.714\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"ps_test, ys_test = evaluate(model, test_loader, device)\nys_test = ys_test.reshape(ps_test.shape)\naucs = []\nfor i in range(ps_test.shape[1]):\n    mask = ys_test[:, i] >= 0\n    if mask.sum() > 0:\n        aucs.append(roc_auc_score(ys_test[mask, i], ps_test[mask, i]))\nprint(f\"Testing | Loss: {loss:.4f} | Test AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T03:12:29.160277Z","iopub.execute_input":"2025-05-26T03:12:29.160969Z","iopub.status.idle":"2025-05-26T03:12:29.490113Z","shell.execute_reply.started":"2025-05-26T03:12:29.160945Z","shell.execute_reply":"2025-05-26T03:12:29.489440Z"}},"outputs":[{"name":"stdout","text":"Testing | Loss: 0.1660 | Test AUC: 0.715\n","output_type":"stream"}],"execution_count":20}]}