{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["VC6dgzIvNpYm","JLWC-e33ywAM","0E9B-fNYOB3q","rQFEcuNXpE8C"],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tox21 GINENet\n\nWe’re solving a multi-task binary toxicity prediction problem on Tox21. Concretely, for each molecule the model outputs 12 probabilities, one for each assay (e.g. NR-AR, SR-ARE, p53, etc.). At training time we use a binary cross-entropy loss (with masking for missing labels) over those 12 tasks, and at the end of each epoch we compute the ROC-AUC per task (then average) on the held-out validation set to see how well the model is distinguishing actives vs. inactives across all assays.","metadata":{"id":"VC6dgzIvNpYm"}},{"cell_type":"code","source":"%pip -q install rdkit-pypi torch_geometric pennylane","metadata":{"id":"l0Z81NMxoiW9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e17f73e4-4830-4b56-b3bc-34550217458f","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:00:56.693762Z","iopub.execute_input":"2025-05-30T13:00:56.694226Z","iopub.status.idle":"2025-05-30T13:01:07.750478Z","shell.execute_reply.started":"2025-05-30T13:00:56.694197Z","shell.execute_reply":"2025-05-30T13:01:07.749474Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom math import ceil\n\n# PennyLane Imports\nimport pennylane as qml\nfrom pennylane import numpy as np\nfrom pennylane.templates import AngleEmbedding, StronglyEntanglingLayers\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Subset, WeightedRandomSampler\nfrom torch.serialization import safe_globals, add_safe_globals\n\n# Pytorch Geometric Imports\nfrom torch_geometric.data import InMemoryDataset, Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.data.data import DataTensorAttr, DataEdgeAttr\nfrom torch_geometric.data.storage import GlobalStorage\nfrom torch_geometric.nn import (\n    GINEConv,\n    GatedGraphConv,\n    Set2Set,\n    GlobalAttention,\n    global_add_pool\n)\nfrom torch_geometric.nn.models import JumpingKnowledge\n\n# RDKit Imports\nfrom rdkit.Chem.Scaffolds import MurckoScaffold\nfrom rdkit.Chem import MolFromSmiles, MolToSmiles, rdchem\nfrom rdkit.Chem import Descriptors\n\nfrom sklearn.metrics import roc_auc_score\nimport os","metadata":{"id":"TmEESHMxt72N","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:01:07.752065Z","iopub.execute_input":"2025-05-30T13:01:07.752302Z","iopub.status.idle":"2025-05-30T13:01:18.593174Z","shell.execute_reply.started":"2025-05-30T13:01:07.752278Z","shell.execute_reply":"2025-05-30T13:01:18.592371Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pennylane/capture/capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.5.2 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!wget wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/tox21.csv.gz\n!gunzip tox21.csv.gz\n!mkdir -p raw\n!mv tox21.csv raw/","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4dsjviCYyJpu","outputId":"1df76760-1456-4190-c35e-e668485b0878","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:01:18.594054Z","iopub.execute_input":"2025-05-30T13:01:18.594617Z","iopub.status.idle":"2025-05-30T13:01:19.879747Z","shell.execute_reply.started":"2025-05-30T13:01:18.594588Z","shell.execute_reply":"2025-05-30T13:01:19.878760Z"}},"outputs":[{"name":"stdout","text":"--2025-05-30 13:01:18--  http://wget/\nResolving wget (wget)... failed: Name or service not known.\nwget: unable to resolve host address ‘wget’\n--2025-05-30 13:01:18--  https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/tox21.csv.gz\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 125310 (122K) [application/octet-stream]\nSaving to: ‘tox21.csv.gz’\n\ntox21.csv.gz        100%[===================>] 122.37K  --.-KB/s    in 0.08s   \n\n2025-05-30 13:01:19 (1.54 MB/s) - ‘tox21.csv.gz’ saved [125310/125310]\n\nFINISHED --2025-05-30 13:01:19--\nTotal wall clock time: 0.7s\nDownloaded: 1 files, 122K in 0.08s (1.54 MB/s)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"add_safe_globals([DataTensorAttr, DataEdgeAttr, GlobalStorage])","metadata":{"id":"D1iG2mLOokTP","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:01:19.881580Z","iopub.execute_input":"2025-05-30T13:01:19.881832Z","iopub.status.idle":"2025-05-30T13:01:19.886348Z","shell.execute_reply.started":"2025-05-30T13:01:19.881809Z","shell.execute_reply":"2025-05-30T13:01:19.885610Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class Tox21Dataset(InMemoryDataset):\n    def __init__(self, root: str = '.', transform=None, pre_transform=None):\n        \"\"\"\n        Expects:\n        root/\n            raw/tox21.csv\n        Will create:\n            processed/data.pt\n        \"\"\"\n        super().__init__(root, transform, pre_transform)\n        # Load the processed data\n        with safe_globals([DataTensorAttr, DataEdgeAttr, GlobalStorage]):\n            self.data, self.slices = torch.load(self.processed_paths[0])\n\n    @property\n    def raw_file_names(self):\n        # File expected in root/raw/\n        return ['tox21.csv']\n\n    @property\n    def processed_file_names(self):\n        return ['data.pt']\n\n    def download(self):\n        # No download step needed; CSV is already in place\n        return\n\n    def process(self):\n        df = pd.read_csv(self.raw_paths[0])\n        df = df.fillna(value=0)\n        \n        if \"mol_id\" in df.columns:\n            df = df.drop(columns=[\"mol_id\"])\n\n        # 3) convert all non-smiles columns to numeric\n        non_smiles = [c for c in df.columns if c != \"smiles\"]\n        df[non_smiles] = df[non_smiles].apply(pd.to_numeric, errors=\"coerce\")\n        df = df.reset_index(drop=True)\n\n        data_list = []\n        bond_types = [\n            rdchem.BondType.SINGLE,\n            rdchem.BondType.DOUBLE,\n            rdchem.BondType.TRIPLE,\n            rdchem.BondType.AROMATIC,\n        ]\n        stereo_types = [\n            rdchem.BondStereo.STEREONONE,\n            rdchem.BondStereo.STEREOZ,\n            rdchem.BondStereo.STEREOE,\n            rdchem.BondStereo.STEREOANY\n        ]\n\n        for _, row in df.iterrows():\n            smiles = row[\"smiles\"]\n            mol = MolFromSmiles(smiles, sanitize=True)\n            if mol is None:\n                continue\n\n            # node features x\n            atom_feats = [\n                [\n                    a.GetAtomicNum(),\n                    a.GetDegree(),\n                    a.GetFormalCharge(),\n                    a.GetNumRadicalElectrons(),\n                    a.GetTotalNumHs(),\n                    int(a.GetIsAromatic()),\n                    int(a.IsInRing())\n                ]\n                for a in mol.GetAtoms()\n            ]\n            x = torch.tensor(atom_feats, dtype=torch.float32)\n\n            # get molecule descriptors\n            descriptors = [\n                Descriptors.MolWt(mol),\n                Descriptors.MolLogP(mol),\n                Descriptors.TPSA(mol),\n                Descriptors.NumHAcceptors(mol),\n                Descriptors.NumHDonors(mol)\n            ]\n\n            # build edge_index AND edge_attr in lock‐step\n            edge_index = []\n            edge_attr  = []\n            for bond in mol.GetBonds():\n                i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n                # one‐hot encode this bond’s type\n                bt = bond.GetBondType()\n                bfeat = [int(bt == t) for t in bond_types]\n                st = bond.GetStereo()\n                sfeat = [int(st == s) for s in stereo_types]\n                feat = bfeat + sfeat\n\n                # add both directions\n                edge_index += [[i, j], [j, i]]\n                edge_attr  += [feat, feat]\n\n            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n            edge_attr  = torch.tensor(edge_attr, dtype=torch.float32)  # [2E, len(bond_types)]\n            desc = torch.tensor(descriptors, dtype=torch.float32)\n\n            # your labels\n            y = torch.tensor(row[[c for c in df.columns if c!=\"smiles\"]].tolist(), dtype=torch.float32)\n\n            \n            data_list.append(Data(\n                x=x,\n                edge_index=edge_index,\n                edge_attr=edge_attr,\n                y=y,\n                desc=desc\n            ))\n\n        data, slices = self.collate(data_list)\n        torch.save((data, slices), self.processed_paths[0])\n","metadata":{"id":"hVOQwpZ4yd21","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:01:20.149056Z","iopub.execute_input":"2025-05-30T13:01:20.149338Z","iopub.status.idle":"2025-05-30T13:01:20.163760Z","shell.execute_reply.started":"2025-05-30T13:01:20.149315Z","shell.execute_reply":"2025-05-30T13:01:20.162974Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"dataset = Tox21Dataset('.')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kTlchDlGFb1w","outputId":"ee3391fe-ad31-45d1-a11d-37ee5300bea3","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:01:24.233461Z","iopub.execute_input":"2025-05-30T13:01:24.234198Z","iopub.status.idle":"2025-05-30T13:01:36.835123Z","shell.execute_reply.started":"2025-05-30T13:01:24.234173Z","shell.execute_reply":"2025-05-30T13:01:36.834344Z"}},"outputs":[{"name":"stderr","text":"Processing...\n[13:01:24] WARNING: not removing hydrogen atom without neighbors\nDone!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"A **Murcko Scaffold** is a technique used to group molecules based on their core structural components. It identifies the essential building blocks by removing side chains and other non-core components, leaving behind the important ring systems and connecting chains. This method is widely used in medicinal chemistry and drug design to identify core structures that have preferential activity against specific targets, which is very useful in **molecular property prediction**.","metadata":{"id":"KjA7GOcFVrTE"}},{"cell_type":"code","source":"def GetMurckoScaffold(data, train_frac: float, val_frac: float, test_frac: float):\n    scaffold_indices = {}\n    for idx, smiles in enumerate(data):\n        scaffold_smiles = MurckoScaffold.MurckoScaffoldSmiles(smiles)\n        #scaffold_smiles = MolToSmiles(scaffold)\n        scaffold_indices.setdefault(scaffold_smiles, []).append(idx)\n\n    groups = sorted(scaffold_indices.values(), key=len, reverse=True)\n    n_total = len(data)\n    n_train = int(train_frac * n_total)\n    n_valid = int(val_frac * n_total)\n\n    train_idx, valid_idx, test_idx = [], [], []\n    for group in groups:\n        if len(train_idx) + len(group) <= n_train:\n            train_idx.extend(group)\n        elif len(valid_idx) + len(group) <= n_valid:\n            valid_idx.extend(group)\n        else:\n            test_idx.extend(group)\n\n    return train_idx, valid_idx, test_idx","metadata":{"id":"enkTOWoRzMiq","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:01:36.836373Z","iopub.execute_input":"2025-05-30T13:01:36.836887Z","iopub.status.idle":"2025-05-30T13:01:36.842175Z","shell.execute_reply.started":"2025-05-30T13:01:36.836867Z","shell.execute_reply":"2025-05-30T13:01:36.841535Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"np.random.seed(3411)\ntorch.manual_seed(3411)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:02:01.468026Z","iopub.execute_input":"2025-05-30T13:02:01.468543Z","iopub.status.idle":"2025-05-30T13:02:01.480233Z","shell.execute_reply.started":"2025-05-30T13:02:01.468520Z","shell.execute_reply":"2025-05-30T13:02:01.479723Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7cfec360c710>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def QLinearCircuit(dev, num_qubits):\n    @qml.qnode(dev, interface='torch')\n    def func(inputs, weights):\n        AngleEmbedding(\n            features=inputs,\n            wires=range(num_qubits),\n            rotation='Y'\n        )\n        StronglyEntanglingLayers(\n            weights=weights,\n            wires=range(num_qubits),\n            imprimitive=qml.CNOT,\n        )\n        return [qml.expval(qml.PauliZ(w)) for w in range(num_qubits)]\n\n    return qml.qnn.TorchLayer(func, {\"weights\": (1, num_qubits, 3)})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:02:02.413213Z","iopub.execute_input":"2025-05-30T13:02:02.413810Z","iopub.status.idle":"2025-05-30T13:02:02.418383Z","shell.execute_reply.started":"2025-05-30T13:02:02.413787Z","shell.execute_reply":"2025-05-30T13:02:02.417685Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class QReLU(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.C1 = torch.tensor(0.01)\n        self.C2 = torch.tensor(2)\n\n    def forward(self, x):\n        return torch.where(\n            x <= 0,\n            self.C1 * x - self.C2 * x,\n            x\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:02:04.601623Z","iopub.execute_input":"2025-05-30T13:02:04.601888Z","iopub.status.idle":"2025-05-30T13:02:04.606045Z","shell.execute_reply.started":"2025-05-30T13:02:04.601871Z","shell.execute_reply":"2025-05-30T13:02:04.605442Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class SmallQNN(nn.Module):\n    def __init__(self, num_qubits: int):\n        super().__init__()\n        qdev = qml.device('default.qubit', wires=range(num_qubits))\n        self.qfunc = QLinearCircuit(qdev, num_qubits)\n        self.qrelu = QReLU()\n        self.bn_gate = nn.BatchNorm1d(num_qubits)\n        self.in_channels = num_qubits\n\n    def forward(self, inputs):\n        x = self.qfunc(inputs)\n        x = self.bn_gate(x)\n        return self.qrelu(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:02:06.562179Z","iopub.execute_input":"2025-05-30T13:02:06.562746Z","iopub.status.idle":"2025-05-30T13:02:06.569272Z","shell.execute_reply.started":"2025-05-30T13:02:06.562721Z","shell.execute_reply":"2025-05-30T13:02:06.568738Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class GINE(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,\n        hidden_dim: int,\n        desc_dim: int,\n        num_tasks: int,\n        n_layers: int,\n        set2set_steps: int = 3,\n    ):\n        super().__init__()\n        \n        # First GINE layer\n        self.conv1 = GINEConv(\n            nn.Sequential(\n                nn.Linear(input_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim)\n            ),\n            edge_dim=8\n        )\n\n        # Additional GINE layers with skip connections\n        self.conv_block = nn.ModuleList()\n        for _ in range(n_layers):\n            mlp = nn.Sequential(\n                nn.Linear(hidden_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            )\n            self.conv_block.append(GINEConv(mlp, edge_dim=8))\n\n        # Optional gated updates\n        self.gate = GatedGraphConv(hidden_dim, 3)\n        self.bn_gate = nn.BatchNorm1d(hidden_dim)\n\n        # Replace mean pool with Set2Set\n        self.pool = Set2Set(hidden_dim, processing_steps=set2set_steps)\n\n        # Fully connected: include descriptor dimension\n        self.fc = nn.Linear(2 * hidden_dim + desc_dim, num_tasks)\n\n    def forward(self, x, edge_index, edge_attr, batch, descriptors):\n        # 1st GINE layer\n        x = self.conv1(x, edge_index, edge_attr)\n\n        # GINE layers + skip connections + dropout\n        for block in self.conv_block:\n            h = block(x, edge_index, edge_attr)\n            x = (x + h).relu()\n            x = F.dropout(x, p=0.1, training=self.training)\n    \n        # (Optional) gated graph conv and BN\n        x = self.gate(x, edge_index)\n        x = self.bn_gate(x)\n\n        # Set2Set pooling: output shape [batch_size, 2*hidden_dim]\n        x = self.pool(x, batch)\n\n        # Concatenate descriptor features\n        # descriptors should be shape [batch_size, desc_dim]\n        descs = descriptors.view(-1, 5)\n        x = torch.cat([x, descs], dim=1)\n\n        # Final prediction\n        return self.fc(x)","metadata":{"id":"gWhA6HDyMM5J","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:02:16.081837Z","iopub.execute_input":"2025-05-30T13:02:16.082489Z","iopub.status.idle":"2025-05-30T13:02:16.091067Z","shell.execute_reply.started":"2025-05-30T13:02:16.082465Z","shell.execute_reply":"2025-05-30T13:02:16.090430Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def train_epoch(model, loader, optimizer, criterion, device, use_desc=True):\n    model.train()\n    total_loss = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        if use_desc:\n            logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch.desc)\n        else:\n            logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n        mask = (batch.y >= 0).float()\n        bs, nt = logits.size()\n        batch_y = batch.y.view(bs, nt)\n        mask = mask.view(bs, nt)\n        loss = (criterion(logits, batch_y) * mask).sum() / mask.sum()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch.num_graphs\n    return total_loss / len(loader.dataset)","metadata":{"id":"QI3ge3gPRtHb","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:02:18.312243Z","iopub.execute_input":"2025-05-30T13:02:18.312976Z","iopub.status.idle":"2025-05-30T13:02:18.318578Z","shell.execute_reply.started":"2025-05-30T13:02:18.312953Z","shell.execute_reply":"2025-05-30T13:02:18.317746Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def evaluate(model, loader, device, use_desc=True):\n    model.eval()\n    y, preds = [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            if use_desc:\n                logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch.desc)\n            else:\n                logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n            y.append(batch.y.cpu())\n            preds.append(torch.sigmoid(logits).cpu())\n    return torch.cat(preds, dim=0).numpy(), torch.cat(y, dim=0).numpy()","metadata":{"id":"Ldql5-B3o-LB","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:02:18.638249Z","iopub.execute_input":"2025-05-30T13:02:18.638725Z","iopub.status.idle":"2025-05-30T13:02:18.643582Z","shell.execute_reply.started":"2025-05-30T13:02:18.638701Z","shell.execute_reply":"2025-05-30T13:02:18.642879Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df = pd.read_csv('raw/tox21.csv').fillna(0).reset_index(drop=True)\nsmiles_list = df['smiles'].tolist()\ntrain_idx, valid_idx, test_idx = GetMurckoScaffold(smiles_list, 0.8, 0.1, 0.1)\n\ntrain_ds = Subset(dataset, train_idx)\nval_ds   = Subset(dataset, valid_idx)\ntest_ds  = Subset(dataset, test_idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)#, sampler=sampler)\nval_loader   = DataLoader(val_ds,   batch_size=32, shuffle=True)\ntest_loader  = DataLoader(test_ds,  batch_size=32)\n\nsample = dataset[0]\nin_channels = sample.x.size(1)\nnum_tasks   = sample.y.size(0)\ndesc_dim = sample.desc.size(0)\n\nprint(\"There are\", num_tasks, \"tasks.\")","metadata":{"id":"Xawk2eEFs2Sm","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:02:21.251938Z","iopub.execute_input":"2025-05-30T13:02:21.252528Z","iopub.status.idle":"2025-05-30T13:02:23.397907Z","shell.execute_reply.started":"2025-05-30T13:02:21.252507Z","shell.execute_reply":"2025-05-30T13:02:23.397291Z"}},"outputs":[{"name":"stderr","text":"[13:02:21] WARNING: not removing hydrogen atom without neighbors\n","output_type":"stream"},{"name":"stdout","text":"There are 12 tasks.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:02:34.356969Z","iopub.execute_input":"2025-05-30T13:02:34.357252Z","iopub.status.idle":"2025-05-30T13:02:34.362085Z","shell.execute_reply.started":"2025-05-30T13:02:34.357230Z","shell.execute_reply":"2025-05-30T13:02:34.361222Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, logits, targets):\n        # logits: shape [N, ...], raw outputs\n        # targets: same shape, 0 or 1\n        probas = torch.sigmoid(logits)\n        # p_t: prob of true class\n        p_t = probas * targets + (1 - probas) * (1 - targets)\n        # alpha factor\n        alpha_factor = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n        # focal weight\n        focal_weight = alpha_factor * (1 - p_t) ** self.gamma\n        # binary cross‐entropy per example\n        bce = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n        loss = focal_weight * bce\n\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        else:\n            return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:02:54.242386Z","iopub.execute_input":"2025-05-30T13:02:54.243266Z","iopub.status.idle":"2025-05-30T13:02:54.249053Z","shell.execute_reply.started":"2025-05-30T13:02:54.243239Z","shell.execute_reply":"2025-05-30T13:02:54.248268Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# Model 1: Classic GINE ","metadata":{}},{"cell_type":"code","source":"model = GINE(\n    in_channels,\n    hidden_dim = 384,\n    num_tasks = num_tasks,\n    desc_dim = desc_dim,\n    n_layers = 3\n).to(device)\n\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:02:36.265221Z","iopub.execute_input":"2025-05-30T13:02:36.265828Z","iopub.status.idle":"2025-05-30T13:02:36.646356Z","shell.execute_reply.started":"2025-05-30T13:02:36.265797Z","shell.execute_reply":"2025-05-30T13:02:36.645611Z"}},"outputs":[{"name":"stdout","text":"GINE(\n  (conv1): GINEConv(nn=Sequential(\n    (0): Linear(in_features=7, out_features=384, bias=True)\n    (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Linear(in_features=384, out_features=384, bias=True)\n  ))\n  (conv_block): ModuleList(\n    (0-2): 3 x GINEConv(nn=Sequential(\n      (0): Linear(in_features=384, out_features=384, bias=True)\n      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=384, out_features=384, bias=True)\n    ))\n  )\n  (gate): GatedGraphConv(384, num_layers=3)\n  (bn_gate): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool): Set2Set(384, 768)\n  (fc): Linear(in_features=773, out_features=12, bias=True)\n)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"optimizer = optim.AdamW(\n    model.parameters(),\n    lr=1e-4,\n    weight_decay=1e-5,\n)\n\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode=\"max\",           # we track val AUC, so “max”\n    factor=0.5,           # halve the lr\n    patience=5,           # after 5 epochs with no AUC gain\n    min_lr=1e-6\n)\n\ncriterion = FocalLoss(alpha=0.10, gamma=1.0, reduction='none')","metadata":{"id":"KjGvP1-jwVFM","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:02:59.390625Z","iopub.execute_input":"2025-05-30T13:02:59.391082Z","iopub.status.idle":"2025-05-30T13:02:59.397825Z","shell.execute_reply.started":"2025-05-30T13:02:59.391055Z","shell.execute_reply":"2025-05-30T13:02:59.396824Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"for epoch in range(1, 21):\n    loss = train_epoch(model, train_loader, optimizer, criterion, device)\n    ps_val, ys_val = evaluate(model, val_loader, device)\n    ys_val = ys_val.reshape(ps_val.shape)\n    aucs = []\n    for i in range(ps_val.shape[1]):\n        mask = ys_val[:, i] >= 0\n        if mask.sum() > 0:\n            aucs.append(roc_auc_score(ys_val[mask, i], ps_val[mask, i]))\n    scheduler.step(np.mean(aucs)) # we use the mean like below\n    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Val AUC: {np.mean(aucs):.3f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"gp_XvcMsw8jW","outputId":"0af71082-b925-49a3-edc8-f8c8569144f3","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:03:09.265303Z","iopub.execute_input":"2025-05-30T13:03:09.266024Z","iopub.status.idle":"2025-05-30T13:04:26.456255Z","shell.execute_reply.started":"2025-05-30T13:03:09.265998Z","shell.execute_reply":"2025-05-30T13:04:26.455442Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Loss: 0.1738 | Val AUC: 0.555\nEpoch 02 | Loss: 0.0341 | Val AUC: 0.610\nEpoch 03 | Loss: 0.0276 | Val AUC: 0.586\nEpoch 04 | Loss: 0.0254 | Val AUC: 0.631\nEpoch 05 | Loss: 0.0224 | Val AUC: 0.653\nEpoch 06 | Loss: 0.0207 | Val AUC: 0.658\nEpoch 07 | Loss: 0.0195 | Val AUC: 0.673\nEpoch 08 | Loss: 0.0184 | Val AUC: 0.680\nEpoch 09 | Loss: 0.0177 | Val AUC: 0.678\nEpoch 10 | Loss: 0.0175 | Val AUC: 0.680\nEpoch 11 | Loss: 0.0171 | Val AUC: 0.693\nEpoch 12 | Loss: 0.0168 | Val AUC: 0.699\nEpoch 13 | Loss: 0.0167 | Val AUC: 0.700\nEpoch 14 | Loss: 0.0164 | Val AUC: 0.688\nEpoch 15 | Loss: 0.0162 | Val AUC: 0.697\nEpoch 16 | Loss: 0.0163 | Val AUC: 0.703\nEpoch 17 | Loss: 0.0165 | Val AUC: 0.707\nEpoch 18 | Loss: 0.0159 | Val AUC: 0.700\nEpoch 19 | Loss: 0.0157 | Val AUC: 0.703\nEpoch 20 | Loss: 0.0157 | Val AUC: 0.711\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"ps_test, ys_test = evaluate(model, test_loader, device)\nys_test = ys_test.reshape(ps_test.shape)\naucs = []\nfor i in range(ps_test.shape[1]):\n    mask = ys_test[:, i] >= 0\n    if mask.sum() > 0:\n        aucs.append(roc_auc_score(ys_test[mask, i], ps_test[mask, i]))\nprint(f\"Testing | Loss: {loss:.4f} | Test AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:07:24.433723Z","iopub.execute_input":"2025-05-30T13:07:24.434298Z","iopub.status.idle":"2025-05-30T13:07:24.787330Z","shell.execute_reply.started":"2025-05-30T13:07:24.434274Z","shell.execute_reply":"2025-05-30T13:07:24.786695Z"}},"outputs":[{"name":"stdout","text":"Testing | Loss: 0.0157 | Test AUC: 0.711\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# Model 2: GINE with Jumping Knowledge","metadata":{}},{"cell_type":"code","source":"class GINEWithJK(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,\n        hidden_dim: int,\n        num_tasks: int,\n        n_layers: int,\n        jk_mode: str = 'cat',\n        set2set_steps: int = 3,\n        use_set2set: bool = True,\n    ):\n        super().__init__()\n        self.n_layers = n_layers\n        self.use_set2set = use_set2set\n\n        # first GINE\n        self.conv1 = GINEConv(\n            nn.Sequential(\n                nn.Linear(input_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            ),\n            edge_dim=8,\n        )\n\n        # additional GINE layers\n        self.convs = nn.ModuleList()\n        for _ in range(n_layers):\n            mlp = nn.Sequential(\n                nn.Linear(hidden_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            )\n            self.convs.append(GINEConv(mlp, edge_dim=8))\n\n        # Jumping Knowledge to concat all layer outputs\n        self.jk = JumpingKnowledge(mode=jk_mode, channels=hidden_dim, num_layers=n_layers+1)\n\n        # pooling: either Set2Set or mean\n        if use_set2set:\n            # input to Set2Set is hidden_dim * (n_layers+1)\n            self.pool = Set2Set(hidden_dim * (n_layers + 1), processing_steps=set2set_steps)\n            # final linear sees 2x that dim\n            fc_in_dim = 2 * hidden_dim * (n_layers + 1)\n        else:\n            self.pool = global_mean_pool\n            fc_in_dim = hidden_dim * (n_layers + 1)\n\n        # final FC\n        self.fc = nn.Linear(fc_in_dim, num_tasks)\n\n    def forward(self, x, edge_index, edge_attr, batch):\n        xs = []\n\n        # layer 0\n        x0 = F.relu(self.conv1(x, edge_index, edge_attr))\n        xs.append(x0)\n\n        # layers 1…n\n        x = x0\n        for conv in self.convs:\n            x = F.relu(conv(x, edge_index, edge_attr))\n            xs.append(x)\n\n        # Jumping Knowledge aggregation (e.g. cat)\n        x_jk = self.jk(xs)  # -> [num_nodes, hidden_dim*(n_layers+1)]\n\n        # graph-level pooling\n        if self.use_set2set:\n            # Set2Set returns [batch_size, 2 * hidden_dim * (n_layers+1)]\n            x_graph = self.pool(x_jk, batch)\n        else:\n            x_graph = self.pool(x_jk, batch)  # global_mean_pool\n\n        # final predictions\n        out = self.fc(x_graph)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:12:30.987028Z","iopub.execute_input":"2025-05-30T13:12:30.987324Z","iopub.status.idle":"2025-05-30T13:12:30.996008Z","shell.execute_reply.started":"2025-05-30T13:12:30.987302Z","shell.execute_reply":"2025-05-30T13:12:30.995237Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"jk_model = GINEWithJK(\n    in_channels,\n    hidden_dim = 384,\n    num_tasks = num_tasks,\n    n_layers = 3,\n    jk_mode = 'cat',\n    set2set_steps = 3,\n).to(device)\n\nprint(jk_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:12:34.384374Z","iopub.execute_input":"2025-05-30T13:12:34.384684Z","iopub.status.idle":"2025-05-30T13:12:34.848234Z","shell.execute_reply.started":"2025-05-30T13:12:34.384661Z","shell.execute_reply":"2025-05-30T13:12:34.847425Z"}},"outputs":[{"name":"stdout","text":"GINEWithJK(\n  (conv1): GINEConv(nn=Sequential(\n    (0): Linear(in_features=7, out_features=384, bias=True)\n    (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Linear(in_features=384, out_features=384, bias=True)\n  ))\n  (convs): ModuleList(\n    (0-2): 3 x GINEConv(nn=Sequential(\n      (0): Linear(in_features=384, out_features=384, bias=True)\n      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=384, out_features=384, bias=True)\n    ))\n  )\n  (jk): JumpingKnowledge(cat)\n  (pool): Set2Set(1536, 3072)\n  (fc): Linear(in_features=3072, out_features=12, bias=True)\n)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"jk_optimizer = optim.AdamW(\n    jk_model.parameters(),\n    lr=3e-4,\n    weight_decay=1e-5,\n)\n\njk_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    jk_optimizer,\n    mode=\"max\",           # we track val AUC, so “max”\n    factor=0.5,           # halve the lr\n    patience=5,           # after 5 epochs with no AUC gain\n    min_lr=1e-6\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:12:40.562843Z","iopub.execute_input":"2025-05-30T13:12:40.563395Z","iopub.status.idle":"2025-05-30T13:12:40.567679Z","shell.execute_reply.started":"2025-05-30T13:12:40.563374Z","shell.execute_reply":"2025-05-30T13:12:40.566937Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"jk_criterion = FocalLoss(alpha=0.10, gamma=1.0, reduction='none')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:12:40.881799Z","iopub.execute_input":"2025-05-30T13:12:40.882398Z","iopub.status.idle":"2025-05-30T13:12:40.885837Z","shell.execute_reply.started":"2025-05-30T13:12:40.882378Z","shell.execute_reply":"2025-05-30T13:12:40.884982Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"for epoch in range(1, 21):\n    loss = train_epoch(jk_model, train_loader, jk_optimizer, jk_criterion, device, False)\n    ps_val, ys_val = evaluate(jk_model, val_loader, device, False)\n    ys_val = ys_val.reshape(ps_val.shape)\n    aucs = []\n    for i in range(ps_val.shape[1]):\n        mask = ys_val[:, i] >= 0\n        if mask.sum() > 0:\n            aucs.append(roc_auc_score(ys_val[mask, i], ps_val[mask, i]))\n    jk_scheduler.step(np.mean(aucs)) # we use the mean like below\n    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Val AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:12:41.546644Z","iopub.execute_input":"2025-05-30T13:12:41.546896Z","iopub.status.idle":"2025-05-30T13:14:45.294626Z","shell.execute_reply.started":"2025-05-30T13:12:41.546878Z","shell.execute_reply":"2025-05-30T13:14:45.293921Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Loss: 0.0225 | Val AUC: 0.633\nEpoch 02 | Loss: 0.0173 | Val AUC: 0.669\nEpoch 03 | Loss: 0.0167 | Val AUC: 0.648\nEpoch 04 | Loss: 0.0166 | Val AUC: 0.672\nEpoch 05 | Loss: 0.0164 | Val AUC: 0.699\nEpoch 06 | Loss: 0.0161 | Val AUC: 0.700\nEpoch 07 | Loss: 0.0160 | Val AUC: 0.695\nEpoch 08 | Loss: 0.0158 | Val AUC: 0.703\nEpoch 09 | Loss: 0.0155 | Val AUC: 0.700\nEpoch 10 | Loss: 0.0154 | Val AUC: 0.701\nEpoch 11 | Loss: 0.0154 | Val AUC: 0.709\nEpoch 12 | Loss: 0.0151 | Val AUC: 0.704\nEpoch 13 | Loss: 0.0150 | Val AUC: 0.700\nEpoch 14 | Loss: 0.0149 | Val AUC: 0.696\nEpoch 15 | Loss: 0.0146 | Val AUC: 0.707\nEpoch 16 | Loss: 0.0147 | Val AUC: 0.704\nEpoch 17 | Loss: 0.0145 | Val AUC: 0.715\nEpoch 18 | Loss: 0.0142 | Val AUC: 0.724\nEpoch 19 | Loss: 0.0141 | Val AUC: 0.715\nEpoch 20 | Loss: 0.0138 | Val AUC: 0.695\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"ps_test, ys_test = evaluate(jk_model, test_loader, device, False)\nys_test = ys_test.reshape(ps_test.shape)\naucs = []\nfor i in range(ps_test.shape[1]):\n    mask = ys_test[:, i] >= 0\n    if mask.sum() > 0:\n        aucs.append(roc_auc_score(ys_test[mask, i], ps_test[mask, i]))\nprint(f\"Testing | Loss: {loss:.4f} | Test AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:14:55.525649Z","iopub.execute_input":"2025-05-30T13:14:55.526384Z","iopub.status.idle":"2025-05-30T13:14:55.787227Z","shell.execute_reply.started":"2025-05-30T13:14:55.526359Z","shell.execute_reply":"2025-05-30T13:14:55.786615Z"}},"outputs":[{"name":"stdout","text":"Testing | Loss: 0.0138 | Test AUC: 0.712\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"# Model 3: GINE with QNN as Initial Mixing Layer","metadata":{}},{"cell_type":"code","source":"class GINEWithQNN(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,\n        hidden_dim: int,\n        num_tasks: int,\n        n_layers: int,\n        set2set_steps: int = 3,\n    ):\n        super().__init__()\n        self.n_layers = n_layers\n        self.qnn = SmallQNN(num_qubits=input_dim)\n\n        # first GINE\n        self.conv1 = GINEConv(\n            nn.Sequential(\n                nn.Linear(input_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            ),\n            edge_dim=8,\n        )\n\n        # additional GINE layers\n        self.convs = nn.ModuleList()\n        for _ in range(n_layers):\n            mlp = nn.Sequential(\n                nn.Linear(hidden_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            )\n            self.convs.append(GINEConv(mlp, edge_dim=8))\n\n\n        # pooling: either Set2Set or mean\n        # If using Set2Set, pool_in_dim = hidden_dim*n_layers\n        self.pool = Set2Set(hidden_dim, processing_steps=set2set_steps)\n        # otherwise: self.pool = global_mean_pool\n\n        # final FC — input dim doubles due to Set2Set concat\n        self.fc = nn.Linear(2 * hidden_dim, num_tasks)\n\n    def forward(self, x, edge_index, edge_attr, batch):\n        x = self.qnn(x) # qnn\n\n        # Initial GINEConv Layer\n        x = F.relu(self.conv1(x, edge_index, edge_attr)) \n\n        # Main GINEConv Layers\n        for conv in self.convs:\n            x = F.relu(conv(x, edge_index, edge_attr))\n\n        # Pooling\n        x = self.pool(x, batch)  # -> [batch_size, 2*hidden_dim*(n_layers)]\n\n        # Final prediction\n        return self.fc(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:15:27.287073Z","iopub.execute_input":"2025-05-30T13:15:27.287376Z","iopub.status.idle":"2025-05-30T13:15:27.294698Z","shell.execute_reply.started":"2025-05-30T13:15:27.287355Z","shell.execute_reply":"2025-05-30T13:15:27.293949Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"qnn_model = GINEWithQNN(\n    in_channels,\n    hidden_dim = 384,\n    num_tasks = num_tasks,\n    n_layers = 3,\n    set2set_steps = 3,\n).to(device)\n\nprint(qnn_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:15:33.287608Z","iopub.execute_input":"2025-05-30T13:15:33.287883Z","iopub.status.idle":"2025-05-30T13:15:33.346120Z","shell.execute_reply.started":"2025-05-30T13:15:33.287864Z","shell.execute_reply":"2025-05-30T13:15:33.345404Z"}},"outputs":[{"name":"stdout","text":"GINEWithQNN(\n  (qnn): SmallQNN(\n    (qfunc): <Quantum Torch Layer: func=func>\n    (qrelu): QReLU()\n    (bn_gate): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (conv1): GINEConv(nn=Sequential(\n    (0): Linear(in_features=7, out_features=384, bias=True)\n    (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Linear(in_features=384, out_features=384, bias=True)\n  ))\n  (convs): ModuleList(\n    (0-2): 3 x GINEConv(nn=Sequential(\n      (0): Linear(in_features=384, out_features=384, bias=True)\n      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=384, out_features=384, bias=True)\n    ))\n  )\n  (pool): Set2Set(384, 768)\n  (fc): Linear(in_features=768, out_features=12, bias=True)\n)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"qnn_optimizer = optim.AdamW(\n    qnn_model.parameters(),\n    lr=1e-4,\n    weight_decay=1e-5,\n)\n\nqnn_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    qnn_optimizer,\n    mode=\"max\",           # we track val AUC, so “max”\n    factor=0.5,           # halve the lr\n    patience=5,           # after 5 epochs with no AUC gain\n    min_lr=1e-6\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:15:37.622689Z","iopub.execute_input":"2025-05-30T13:15:37.623349Z","iopub.status.idle":"2025-05-30T13:15:37.627336Z","shell.execute_reply.started":"2025-05-30T13:15:37.623325Z","shell.execute_reply":"2025-05-30T13:15:37.626745Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"qnn_criterion = FocalLoss(alpha=0.38, gamma=0.938, reduction='none')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:23:17.155045Z","iopub.execute_input":"2025-05-30T13:23:17.155328Z","iopub.status.idle":"2025-05-30T13:23:17.159237Z","shell.execute_reply.started":"2025-05-30T13:23:17.155306Z","shell.execute_reply":"2025-05-30T13:23:17.158441Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"for epoch in range(1, 21):\n    loss = train_epoch(qnn_model, train_loader, qnn_optimizer, qnn_criterion, device, False)\n    ps_val, ys_val = evaluate(qnn_model, val_loader, device, False)\n    ys_val = ys_val.reshape(ps_val.shape)\n    aucs = []\n    for i in range(ps_val.shape[1]):\n        mask = ys_val[:, i] >= 0\n        if mask.sum() > 0:\n            aucs.append(roc_auc_score(ys_val[mask, i], ps_val[mask, i]))\n    qnn_scheduler.step(np.mean(aucs)) # we use the mean like below\n    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Val AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:23:18.143638Z","iopub.execute_input":"2025-05-30T13:23:18.143962Z","iopub.status.idle":"2025-05-30T13:26:52.196658Z","shell.execute_reply.started":"2025-05-30T13:23:18.143912Z","shell.execute_reply":"2025-05-30T13:26:52.195991Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Loss: 0.0403 | Val AUC: 0.709\nEpoch 02 | Loss: 0.0392 | Val AUC: 0.710\nEpoch 03 | Loss: 0.0377 | Val AUC: 0.724\nEpoch 04 | Loss: 0.0370 | Val AUC: 0.714\nEpoch 05 | Loss: 0.0354 | Val AUC: 0.724\nEpoch 06 | Loss: 0.0347 | Val AUC: 0.732\nEpoch 07 | Loss: 0.0341 | Val AUC: 0.730\nEpoch 08 | Loss: 0.0336 | Val AUC: 0.718\nEpoch 09 | Loss: 0.0334 | Val AUC: 0.728\nEpoch 10 | Loss: 0.0329 | Val AUC: 0.719\nEpoch 11 | Loss: 0.0325 | Val AUC: 0.716\nEpoch 12 | Loss: 0.0321 | Val AUC: 0.725\nEpoch 13 | Loss: 0.0310 | Val AUC: 0.721\nEpoch 14 | Loss: 0.0306 | Val AUC: 0.723\nEpoch 15 | Loss: 0.0306 | Val AUC: 0.720\nEpoch 16 | Loss: 0.0302 | Val AUC: 0.722\nEpoch 17 | Loss: 0.0299 | Val AUC: 0.718\nEpoch 18 | Loss: 0.0299 | Val AUC: 0.713\nEpoch 19 | Loss: 0.0290 | Val AUC: 0.723\nEpoch 20 | Loss: 0.0288 | Val AUC: 0.720\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"ps_test, ys_test = evaluate(qnn_model, test_loader, device, False)\nys_test = ys_test.reshape(ps_test.shape)\naucs = []\nfor i in range(ps_test.shape[1]):\n    mask = ys_test[:, i] >= 0\n    if mask.sum() > 0:\n        aucs.append(roc_auc_score(ys_test[mask, i], ps_test[mask, i]))\nprint(f\"Testing | Loss: {loss:.4f} | Test AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T13:28:14.897665Z","iopub.execute_input":"2025-05-30T13:28:14.898409Z","iopub.status.idle":"2025-05-30T13:28:15.604829Z","shell.execute_reply.started":"2025-05-30T13:28:14.898384Z","shell.execute_reply":"2025-05-30T13:28:15.604228Z"}},"outputs":[{"name":"stdout","text":"Testing | Loss: 0.0288 | Test AUC: 0.679\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}