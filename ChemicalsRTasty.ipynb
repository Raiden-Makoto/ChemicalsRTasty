{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0Z81NMxoiW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ec1867-1d5c-4995-bfdf-cb0b64099bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip -q install rdkit-pypi torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell below must be run twice for some obscure reason"
      ],
      "metadata": {
        "id": "S3s90ZFaDP3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "TmEESHMxt72N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/tox21.csv.gz\n",
        "!gunzip tox21.csv.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dsjviCYyJpu",
        "outputId": "134bb2b0-6870-4061-e5bc-3ba281058e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-21 03:30:53--  http://wget/\n",
            "Resolving wget (wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘wget’\n",
            "--2025-05-21 03:30:53--  https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/tox21.csv.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 125310 (122K) [application/octet-stream]\n",
            "Saving to: ‘tox21.csv.gz’\n",
            "\n",
            "tox21.csv.gz        100%[===================>] 122.37K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-05-21 03:30:53 (3.24 MB/s) - ‘tox21.csv.gz’ saved [125310/125310]\n",
            "\n",
            "FINISHED --2025-05-21 03:30:53--\n",
            "Total wall clock time: 0.3s\n",
            "Downloaded: 1 files, 122K in 0.04s (3.24 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p raw\n",
        "!mv tox21.csv raw/"
      ],
      "metadata": {
        "id": "en5zEqdpCoiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7befac7e-4667-4836-d35b-353faa14d4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'tox21.csv': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "JLWC-e33ywAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit.Chem import MolFromSmiles, MolToSmiles"
      ],
      "metadata": {
        "id": "HE92FQLqzaFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tox21Dataset(InMemoryDataset):\n",
        "    def __init__(self, root: str = '.', transform=None, pre_transform=None):\n",
        "        \"\"\"\n",
        "        Expects:\n",
        "        root/\n",
        "            raw/tox21.csv\n",
        "        Will create:\n",
        "            processed/data.pt\n",
        "        \"\"\"\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        # Load the processed data\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        # File expected in root/raw/\n",
        "        return ['tox21.csv']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['data.pt']\n",
        "\n",
        "    def download(self):\n",
        "        # No download step needed; CSV is already in place\n",
        "        return\n",
        "\n",
        "    def process(self):\n",
        "        df = pd.read_csv(self.raw_paths[0])\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            smiles = row['smiles']\n",
        "            molecule = MolFromSmiles(smiles, sanitize=True)\n",
        "            if not molecule: continue\n",
        "            atom_features = []\n",
        "\n",
        "            for atom in molecule.GetAtoms():\n",
        "                atom_features.append([\n",
        "                    atom.GetAtomicNum(),\n",
        "                    atom.GetDegree(),\n",
        "                    atom.GetFormalCharge(),\n",
        "                    atom.GetNumRadicalElectrons(),\n",
        "                ])\n",
        "            x = torch.tensor(atom_features, dtype=torch.float32)\n",
        "\n",
        "            edge_index = []\n",
        "            for bond in molecule.GetBonds():\n",
        "                i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "                edge_index.append([i, j])\n",
        "                edge_index.append([j, i])\n",
        "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "            y = torch.tensor(row.iloc[1:].values, dtype=torch.float32)\n",
        "            data = Data(x=x, edge_index=edge_index, y=y)\n",
        "            data_list.append(data)\n",
        "\n",
        "        data, slices = self.collate(data_list)\n",
        "        return data, slices\n"
      ],
      "metadata": {
        "id": "hVOQwpZ4yd21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Tox21Dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "kTlchDlGFb1w",
        "outputId": "980ffbf1-1524-49c9-f237-bcc90b91dcec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "No registered converter was able to produce a C++ rvalue of type std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> > from this Python object of type numpy.float64",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-7e84b221f87f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTox21Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-b1b690da3cfc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprocessed\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \"\"\"\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Load the processed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mforce_reload\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     ) -> None:\n\u001b[0;32m---> 81\u001b[0;31m         super().__init__(root, transform, pre_transform, pre_filter, log,\n\u001b[0m\u001b[1;32m     82\u001b[0m                          force_reload)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pre_transform.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-b1b690da3cfc>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0msmiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smiles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mmolecule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMolFromSmiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmolecule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0matom_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: No registered converter was able to produce a C++ rvalue of type std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> > from this Python object of type numpy.float64"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **Murcko Scaffold** is a technique used to group molecules based on their core structural components. It identifies the essential building blocks by removing side chains and other non-core components, leaving behind the important ring systems and connecting chains. This method is widely used in medicinal chemistry and drug design to identify core structures that have preferential activity against specific targets, which is very useful in **molecular property prediction**."
      ],
      "metadata": {
        "id": "KjA7GOcFVrTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetMurckoScaffold(data, train_frac: float, val_frac: float, test_frac: float):\n",
        "    scaffold_indices = {}\n",
        "    for idx, smiles in enumerate(data):\n",
        "        scaffold_smiles = MurckoScaffold.MurckoScaffoldSmiles(smiles)\n",
        "        #scaffold_smiles = MolToSmiles(scaffold)\n",
        "        scaffold_indices.setdefault(scaffold_smiles, []).append(idx)\n",
        "\n",
        "    groups = sorted(scaffold_indices.values(), key=len, reverse=True)\n",
        "    n_total = len(data)\n",
        "    n_train = int(train_frac * n_total)\n",
        "    n_valid = int(val_frac * n_total)\n",
        "\n",
        "    train_idx, valid_idx, test_idx = [], [], []\n",
        "    for group in groups:\n",
        "        if len(train_idx) + len(group) <= n_train:\n",
        "            train_idx.extend(group)\n",
        "        elif len(valid_idx) + len(group) <= n_valid:\n",
        "            valid_idx.extend(group)\n",
        "        else:\n",
        "            test_idx.extend(group)\n",
        "\n",
        "    return train_idx, valid_idx, test_idx"
      ],
      "metadata": {
        "id": "enkTOWoRzMiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN Model"
      ],
      "metadata": {
        "id": "0E9B-fNYOB3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GINEConv, GatedGraphConv, global_mean_pool"
      ],
      "metadata": {
        "id": "eLUD3lvpQu6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GINEModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_tasks):\n",
        "        super().__init__()\n",
        "        self.conv1 = GINEConv(\n",
        "            nn.Sequential(\n",
        "                nn.Linear(input_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_dim, hidden_dim),\n",
        "            )\n",
        "        )\n",
        "        self.conv2 = GINEConv(\n",
        "            nn.Sequential(\n",
        "                nn.Linear(hidden_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_dim, hidden_dim),\n",
        "            )\n",
        "        )\n",
        "        self.gate = GatedGraphConv(hidden_dim, 2)\n",
        "        self.pool = global_mean_pool\n",
        "        self.fc = nn.Linear(hidden_dim, num_tasks)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
        "        x = self.conv2(x, edge_index, edge_attr).relu()\n",
        "        x = nn.Dropout(0.2)(x)\n",
        "        x = self.gate(x, edge_index).relu()\n",
        "        x = self.pool(x, batch)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "gWhA6HDyMM5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "rQFEcuNXpE8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        if hasattr(batch, 'edge_attr'):\n",
        "            logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
        "        else:\n",
        "            logits = model(batch.x, batch.edge_index, batch.batch)\n",
        "        mask = (batch.y >= 0).float()\n",
        "        loss = (criterion(logits, batch.y) * mask).sum() / mask.sum()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * batch.num_graphs\n",
        "    return total_loss / len(loader.dataset)"
      ],
      "metadata": {
        "id": "QI3ge3gPRtHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    y, preds = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            if hasattr(batch, 'edge_attr'):\n",
        "                logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
        "            else:\n",
        "                logits = model(batch.x, batch.edge_index, batch.batch)\n",
        "            y.append(batch.y.cpu())\n",
        "            preds.append(torch.sigmoid(logits).cpu())\n",
        "    return torch.cat(preds, dim=0).numpy(), torch.cat(y, dim=0).numpy()"
      ],
      "metadata": {
        "id": "Ldql5-B3o-LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "3U04GeF_qONW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('tox21.csv')\n",
        "smiles_list = df['smiles'].tolist()\n",
        "train_idx, valid_idx, test_idx = GetMurckoScaffold(smiles_list, 0.8, 0.1, 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAA5KSKiqJ7o",
        "outputId": "41bad3ba-d1a1-4742-888a-e56e14c72e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[03:22:55] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tox21Dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "5OCZ38GguC1Y",
        "outputId": "2b36154b-c055-4602-d3b8-52d93d5a3f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.Tox21Dataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>Tox21Dataset</b><br/>def __init__(path=&#x27;.&#x27;, transform=None, pre_transform=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\"></a>Dataset base class for creating graph datasets which easily fit\n",
              "into CPU memory.\n",
              "See `here &lt;https://pytorch-geometric.readthedocs.io/en/latest/tutorial/\n",
              "create_dataset.html#creating-in-memory-datasets&gt;`__ for the accompanying\n",
              "tutorial.\n",
              "\n",
              "Args:\n",
              "    root (str, optional): Root directory where the dataset should be saved.\n",
              "        (optional: :obj:`None`)\n",
              "    transform (callable, optional): A function/transform that takes in a\n",
              "        :class:`~torch_geometric.data.Data` or\n",
              "        :class:`~torch_geometric.data.HeteroData` object and returns a\n",
              "        transformed version.\n",
              "        The data object will be transformed before every access.\n",
              "        (default: :obj:`None`)\n",
              "    pre_transform (callable, optional): A function/transform that takes in\n",
              "        a :class:`~torch_geometric.data.Data` or\n",
              "        :class:`~torch_geometric.data.HeteroData` object and returns a\n",
              "        transformed version.\n",
              "        The data object will be transformed before being saved to disk.\n",
              "        (default: :obj:`None`)\n",
              "    pre_filter (callable, optional): A function that takes in a\n",
              "        :class:`~torch_geometric.data.Data` or\n",
              "        :class:`~torch_geometric.data.HeteroData` object and returns a\n",
              "        boolean value, indicating whether the data object should be\n",
              "        included in the final dataset. (default: :obj:`None`)\n",
              "    log (bool, optional): Whether to print any console output while\n",
              "        downloading and processing the dataset. (default: :obj:`True`)\n",
              "    force_reload (bool, optional): Whether to re-process the dataset.\n",
              "        (default: :obj:`False`)</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Tox21Dataset(path='tox21.csv')\n",
        "\n",
        "train_ds = Subset(dataset, train_idx)\n",
        "val_ds   = Subset(dataset, valid_idx)\n",
        "test_ds  = Subset(dataset, test_idx)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=32)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "Xawk2eEFs2Sm",
        "outputId": "98824645-8f91-4afc-a463-90ee855c4a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-e456db707e5b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTox21Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tox21.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_ds\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_ds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-caaa81906f1a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, transform, pre_transform)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTox21Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInMemoryDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mforce_reload\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     ) -> None:\n\u001b[0;32m---> 81\u001b[0;31m         super().__init__(root, transform, pre_transform, pre_filter, log,\n\u001b[0m\u001b[1;32m     82\u001b[0m                          force_reload)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \"`force_reload=True` explicitly to reload the dataset.\")\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_reload\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfiles_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36mprocessed_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_file_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m# Prevent a common source of error in which `file_names` are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# defined as a property.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36mprocessed_file_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocessed_file_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     def __init__(\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9yj5lTQpt55L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}