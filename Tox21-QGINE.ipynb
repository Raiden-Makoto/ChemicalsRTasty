{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["VC6dgzIvNpYm","JLWC-e33ywAM","0E9B-fNYOB3q","rQFEcuNXpE8C"],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tox21 GINENet\n\nWe’re solving a multi-task binary toxicity prediction problem on Tox21. Concretely, for each molecule the model outputs 12 probabilities, one for each assay (e.g. NR-AR, SR-ARE, p53, etc.). At training time we use a binary cross-entropy loss (with masking for missing labels) over those 12 tasks, and at the end of each epoch we compute the ROC-AUC per task (then average) on the held-out validation set to see how well the model is distinguishing actives vs. inactives across all assays.","metadata":{"id":"VC6dgzIvNpYm"}},{"cell_type":"code","source":"%pip -q install rdkit-pypi torch_geometric pennylane","metadata":{"id":"l0Z81NMxoiW9","outputId":"e17f73e4-4830-4b56-b3bc-34550217458f","trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:05:38.679553Z","iopub.execute_input":"2025-06-02T20:05:38.679829Z","iopub.status.idle":"2025-06-02T20:05:49.921191Z","shell.execute_reply.started":"2025-06-02T20:05:38.679803Z","shell.execute_reply":"2025-06-02T20:05:49.920109Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Subset, WeightedRandomSampler\nfrom torch.serialization import safe_globals, add_safe_globals\n\n# Pytorch Geometric Imports\nfrom torch_geometric.data import InMemoryDataset, Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.data.data import DataTensorAttr, DataEdgeAttr\nfrom torch_geometric.data.storage import GlobalStorage\nfrom torch_geometric.nn import (\n    GINEConv,\n    GatedGraphConv,\n    Set2Set,\n    GlobalAttention,\n    global_add_pool,\n    global_mean_pool\n)\nfrom torch_geometric.nn.models import JumpingKnowledge\n\n# RDKit Imports\nfrom rdkit.Chem.Scaffolds import MurckoScaffold\nfrom rdkit.Chem import MolFromSmiles, MolToSmiles, rdchem\nfrom rdkit.Chem import Descriptors\n\nfrom sklearn.metrics import roc_auc_score\nimport os\nimport optuna\nfrom pennylane import numpy as np\nimport pennylane as qml\nfrom pennylane.templates import (\n    AngleEmbedding,\n    AmplitudeEmbedding,\n    StronglyEntanglingLayers\n)\n\nadd_safe_globals([DataTensorAttr, DataEdgeAttr, GlobalStorage])","metadata":{"id":"TmEESHMxt72N","trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:08:09.815769Z","iopub.execute_input":"2025-06-02T20:08:09.816653Z","iopub.status.idle":"2025-06-02T20:08:24.807792Z","shell.execute_reply.started":"2025-06-02T20:08:09.816615Z","shell.execute_reply":"2025-06-02T20:08:24.806924Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pennylane/capture/capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.5.2 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!wget wget https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/tox21.csv.gz\n!gunzip tox21.csv.gz\n!mkdir -p raw\n!mv tox21.csv raw/","metadata":{"id":"4dsjviCYyJpu","outputId":"1df76760-1456-4190-c35e-e668485b0878","trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:09:50.568760Z","iopub.execute_input":"2025-06-02T20:09:50.570005Z","iopub.status.idle":"2025-06-02T20:09:51.434388Z","shell.execute_reply.started":"2025-06-02T20:09:50.569976Z","shell.execute_reply":"2025-06-02T20:09:51.433403Z"}},"outputs":[{"name":"stdout","text":"--2025-06-02 20:09:50--  http://wget/\nResolving wget (wget)... failed: Name or service not known.\nwget: unable to resolve host address ‘wget’\n--2025-06-02 20:09:50--  https://raw.githubusercontent.com/deepchem/deepchem/master/datasets/tox21.csv.gz\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 125310 (122K) [application/octet-stream]\nSaving to: ‘tox21.csv.gz’\n\ntox21.csv.gz        100%[===================>] 122.37K  --.-KB/s    in 0.02s   \n\n2025-06-02 20:09:50 (5.61 MB/s) - ‘tox21.csv.gz’ saved [125310/125310]\n\nFINISHED --2025-06-02 20:09:50--\nTotal wall clock time: 0.3s\nDownloaded: 1 files, 122K in 0.02s (5.61 MB/s)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class Tox21Dataset(InMemoryDataset):\n    def __init__(self, root: str = '.', transform=None, pre_transform=None):\n        \"\"\"\n        Expects:\n        root/\n            raw/tox21.csv\n        Will create:\n            processed/data.pt\n        \"\"\"\n        super().__init__(root, transform, pre_transform)\n        # Load the processed data\n        with safe_globals([DataTensorAttr, DataEdgeAttr, GlobalStorage]):\n            self.data, self.slices = torch.load(self.processed_paths[0])\n\n    @property\n    def raw_file_names(self):\n        # File expected in root/raw/\n        return ['tox21.csv']\n\n    @property\n    def processed_file_names(self):\n        return ['data.pt']\n\n    def download(self):\n        # No download step needed; CSV is already in place\n        return\n\n    def process(self):\n        df = pd.read_csv(self.raw_paths[0])\n        df = df.fillna(value=0)\n        \n        if \"mol_id\" in df.columns:\n            df = df.drop(columns=[\"mol_id\"])\n\n        # 3) convert all non-smiles columns to numeric\n        non_smiles = [c for c in df.columns if c != \"smiles\"]\n        df[non_smiles] = df[non_smiles].apply(pd.to_numeric, errors=\"coerce\")\n        df = df.reset_index(drop=True)\n\n        data_list = []\n        bond_types = [\n            rdchem.BondType.SINGLE,\n            rdchem.BondType.DOUBLE,\n            rdchem.BondType.TRIPLE,\n            rdchem.BondType.AROMATIC,\n        ]\n        stereo_types = [\n            rdchem.BondStereo.STEREONONE,\n            rdchem.BondStereo.STEREOZ,\n            rdchem.BondStereo.STEREOE,\n            rdchem.BondStereo.STEREOANY\n        ]\n\n        for _, row in df.iterrows():\n            smiles = row[\"smiles\"]\n            mol = MolFromSmiles(smiles, sanitize=True)\n            if mol is None:\n                continue\n\n            # node features x\n            atom_feats = [\n                [\n                    a.GetAtomicNum(),\n                    a.GetDegree(),\n                    a.GetFormalCharge(),\n                    a.GetNumRadicalElectrons(),\n                    a.GetTotalNumHs(),\n                    int(a.GetIsAromatic()),\n                    int(a.IsInRing())\n                ]\n                for a in mol.GetAtoms()\n            ]\n            x = torch.tensor(atom_feats, dtype=torch.float32)\n\n            # get molecule descriptors\n            descriptors = [\n                Descriptors.MolWt(mol),\n                Descriptors.MolLogP(mol),\n                Descriptors.TPSA(mol),\n                Descriptors.NumHAcceptors(mol),\n                Descriptors.NumHDonors(mol)\n            ]\n\n            # build edge_index AND edge_attr in lock‐step\n            edge_index = []\n            edge_attr  = []\n            for bond in mol.GetBonds():\n                i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n                # one‐hot encode this bond’s type\n                bt = bond.GetBondType()\n                bfeat = [int(bt == t) for t in bond_types]\n                st = bond.GetStereo()\n                sfeat = [int(st == s) for s in stereo_types]\n                feat = bfeat + sfeat\n\n                # add both directions\n                edge_index += [[i, j], [j, i]]\n                edge_attr  += [feat, feat]\n\n            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n            edge_attr  = torch.tensor(edge_attr, dtype=torch.float32)  # [2E, len(bond_types)]\n            desc = torch.tensor(descriptors, dtype=torch.float32)\n\n            # your labels\n            y = torch.tensor(row[[c for c in df.columns if c!=\"smiles\"]].tolist(), dtype=torch.float32)\n\n            \n            data_list.append(Data(\n                x=x,\n                edge_index=edge_index,\n                edge_attr=edge_attr,\n                y=y,\n                desc=desc\n            ))\n\n        data, slices = self.collate(data_list)\n        torch.save((data, slices), self.processed_paths[0])\n","metadata":{"id":"hVOQwpZ4yd21","trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:09:52.313191Z","iopub.execute_input":"2025-06-02T20:09:52.314097Z","iopub.status.idle":"2025-06-02T20:09:52.328331Z","shell.execute_reply.started":"2025-06-02T20:09:52.314062Z","shell.execute_reply":"2025-06-02T20:09:52.327643Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset = Tox21Dataset('.')","metadata":{"id":"kTlchDlGFb1w","outputId":"ee3391fe-ad31-45d1-a11d-37ee5300bea3","trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:09:54.735586Z","iopub.execute_input":"2025-06-02T20:09:54.735935Z","iopub.status.idle":"2025-06-02T20:10:09.911135Z","shell.execute_reply.started":"2025-06-02T20:09:54.735913Z","shell.execute_reply":"2025-06-02T20:10:09.910067Z"}},"outputs":[{"name":"stderr","text":"Processing...\n[20:09:54] WARNING: not removing hydrogen atom without neighbors\nDone!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"A **Murcko Scaffold** is a technique used to group molecules based on their core structural components. It identifies the essential building blocks by removing side chains and other non-core components, leaving behind the important ring systems and connecting chains. This method is widely used in medicinal chemistry and drug design to identify core structures that have preferential activity against specific targets, which is very useful in **molecular property prediction**.","metadata":{"id":"KjA7GOcFVrTE"}},{"cell_type":"code","source":"def GetMurckoScaffold(data, train_frac: float, val_frac: float, test_frac: float):\n    scaffold_indices = {}\n    for idx, smiles in enumerate(data):\n        scaffold_smiles = MurckoScaffold.MurckoScaffoldSmiles(smiles)\n        #scaffold_smiles = MolToSmiles(scaffold)\n        scaffold_indices.setdefault(scaffold_smiles, []).append(idx)\n\n    groups = sorted(scaffold_indices.values(), key=len, reverse=True)\n    n_total = len(data)\n    n_train = int(train_frac * n_total)\n    n_valid = int(val_frac * n_total)\n\n    train_idx, valid_idx, test_idx = [], [], []\n    for group in groups:\n        if len(train_idx) + len(group) <= n_train:\n            train_idx.extend(group)\n        elif len(valid_idx) + len(group) <= n_valid:\n            valid_idx.extend(group)\n        else:\n            test_idx.extend(group)\n\n    return train_idx, valid_idx, test_idx","metadata":{"id":"enkTOWoRzMiq","trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:10:09.912539Z","iopub.execute_input":"2025-06-02T20:10:09.912900Z","iopub.status.idle":"2025-06-02T20:10:09.922046Z","shell.execute_reply.started":"2025-06-02T20:10:09.912869Z","shell.execute_reply":"2025-06-02T20:10:09.920958Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"np.random.seed(3411)\ntorch.manual_seed(3411)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:10:09.923050Z","iopub.execute_input":"2025-06-02T20:10:09.923324Z","iopub.status.idle":"2025-06-02T20:10:09.947664Z","shell.execute_reply.started":"2025-06-02T20:10:09.923300Z","shell.execute_reply":"2025-06-02T20:10:09.946854Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f1cd57331f0>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def train_epoch(model, loader, optimizer, criterion, device, use_desc=True):\n    model.train()\n    total_loss = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        if use_desc:\n            logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch.desc)\n        else:\n            logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n        mask = (batch.y >= 0).float()\n        bs, nt = logits.size()\n        batch_y = batch.y.view(bs, nt)\n        mask = mask.view(bs, nt)\n        loss = (criterion(logits, batch_y) * mask).sum() / mask.sum()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch.num_graphs\n    return total_loss / len(loader.dataset)\n\ndef evaluate(model, loader, device, use_desc=True):\n    model.eval()\n    y, preds = [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            if use_desc:\n                logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch.desc)\n            else:\n                logits = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n            y.append(batch.y.cpu())\n            preds.append(torch.sigmoid(logits).cpu())\n    return torch.cat(preds, dim=0).numpy(), torch.cat(y, dim=0).numpy()","metadata":{"id":"QI3ge3gPRtHb","trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:10:09.949888Z","iopub.execute_input":"2025-06-02T20:10:09.950155Z","iopub.status.idle":"2025-06-02T20:10:09.959343Z","shell.execute_reply.started":"2025-06-02T20:10:09.950133Z","shell.execute_reply":"2025-06-02T20:10:09.958501Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df = pd.read_csv('raw/tox21.csv').fillna(0).reset_index(drop=True)\nsmiles_list = df['smiles'].tolist()\ntrain_idx, valid_idx, test_idx = GetMurckoScaffold(smiles_list, 0.8, 0.1, 0.1)\n\ntrain_ds = Subset(dataset, train_idx)\nval_ds   = Subset(dataset, valid_idx)\ntest_ds  = Subset(dataset, test_idx)\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)#, sampler=sampler)\nval_loader   = DataLoader(val_ds,   batch_size=32, shuffle=True)\ntest_loader  = DataLoader(test_ds,  batch_size=32)\n\nsample = dataset[0]\nin_channels = sample.x.size(1)\nnum_tasks   = sample.y.size(0)\ndesc_dim = sample.desc.size(0)\n\nprint(\"There are\", num_tasks, \"tasks.\")","metadata":{"id":"Xawk2eEFs2Sm","trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:10:09.960314Z","iopub.execute_input":"2025-06-02T20:10:09.960613Z","iopub.status.idle":"2025-06-02T20:10:12.433450Z","shell.execute_reply.started":"2025-06-02T20:10:09.960567Z","shell.execute_reply":"2025-06-02T20:10:12.432533Z"}},"outputs":[{"name":"stderr","text":"[20:10:10] WARNING: not removing hydrogen atom without neighbors\n","output_type":"stream"},{"name":"stdout","text":"There are 12 tasks.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:10:12.434376Z","iopub.execute_input":"2025-06-02T20:10:12.434719Z","iopub.status.idle":"2025-06-02T20:10:12.439437Z","shell.execute_reply.started":"2025-06-02T20:10:12.434693Z","shell.execute_reply":"2025-06-02T20:10:12.438522Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, logits, targets):\n        # logits: shape [N, ...], raw outputs\n        # targets: same shape, 0 or 1\n        probas = torch.sigmoid(logits)\n        # p_t: prob of true class\n        p_t = probas * targets + (1 - probas) * (1 - targets)\n        # alpha factor\n        alpha_factor = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n        # focal weight\n        focal_weight = alpha_factor * (1 - p_t) ** self.gamma\n        # binary cross‐entropy per example\n        bce = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n        loss = focal_weight * bce\n\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        else:\n            return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:10:12.440448Z","iopub.execute_input":"2025-06-02T20:10:12.440805Z","iopub.status.idle":"2025-06-02T20:10:12.473070Z","shell.execute_reply.started":"2025-06-02T20:10:12.440775Z","shell.execute_reply":"2025-06-02T20:10:12.472126Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# GINE with Jumping Knowledge","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:10:12.474091Z","iopub.execute_input":"2025-06-02T20:10:12.474372Z","iopub.status.idle":"2025-06-02T20:10:12.484725Z","shell.execute_reply.started":"2025-06-02T20:10:12.474350Z","shell.execute_reply":"2025-06-02T20:10:12.483882Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class OriginalGINE(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,\n        num_tasks: int,\n        hidden_dim: int = 300,\n        n_layers: int = 5,\n        jk_mode: str = 'cat',\n        dropout: float = 0.5,\n    ):\n        super().__init__()\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n        self.dropout = dropout\n\n        # Build n_layers GINEConv blocks, each with MLP: Linear→BatchNorm→ReLU→Linear\n        self.convs = nn.ModuleList()\n        for i in range(n_layers):\n            in_dim = input_dim if i == 0 else hidden_dim\n            mlp = nn.Sequential(\n                nn.Linear(in_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            )\n            self.convs.append(GINEConv(mlp, edge_dim=8))\n\n        # JumpingKnowledge over all layer outputs\n        self.jk = JumpingKnowledge(mode=jk_mode, channels=hidden_dim, num_layers=n_layers)\n\n        # Final MLP: (hidden_dim * n_layers) → 128 → num_tasks\n        jk_out_dim = hidden_dim * n_layers if jk_mode == 'cat' else hidden_dim\n        self.lin1 = nn.Linear(jk_out_dim, 128)\n        self.lin2 = nn.Linear(128, num_tasks)\n\n    def forward(self, x, edge_index, edge_attr, batch):\n        xs = []\n        h = x\n        for conv in self.convs:\n            h = conv(h, edge_index, edge_attr)\n            h = F.relu(h)\n            h = F.dropout(h, p=self.dropout, training=self.training)\n            xs.append(h)\n\n        # JumpingKnowledge aggregation\n        h_jk = self.jk(xs)  # shape: [num_nodes, hidden_dim * n_layers] if mode='cat'\n\n        # Graph‐level mean pooling\n        g = global_mean_pool(h_jk, batch)  # [batch_size, jk_out_dim]\n\n        # Final 2‐layer MLP\n        out = F.relu(self.lin1(g))\n        out = F.dropout(out, p=self.dropout, training=self.training)\n        out = self.lin2(out)  # [batch_size, num_tasks]\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:10:12.485702Z","iopub.execute_input":"2025-06-02T20:10:12.486051Z","iopub.status.idle":"2025-06-02T20:10:12.499803Z","shell.execute_reply.started":"2025-06-02T20:10:12.486026Z","shell.execute_reply":"2025-06-02T20:10:12.498844Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"jk_model = OriginalGINE(\n    input_dim = in_channels,\n    num_tasks = num_tasks,\n    hidden_dim = 300,\n    n_layers = 5,\n    jk_mode = 'cat'\n).to(device)\n\nprint(jk_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:10:12.502312Z","iopub.execute_input":"2025-06-02T20:10:12.502652Z","iopub.status.idle":"2025-06-02T20:10:12.773530Z","shell.execute_reply.started":"2025-06-02T20:10:12.502624Z","shell.execute_reply":"2025-06-02T20:10:12.772559Z"}},"outputs":[{"name":"stdout","text":"OriginalGINE(\n  (convs): ModuleList(\n    (0): GINEConv(nn=Sequential(\n      (0): Linear(in_features=7, out_features=300, bias=True)\n      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=300, out_features=300, bias=True)\n    ))\n    (1-4): 4 x GINEConv(nn=Sequential(\n      (0): Linear(in_features=300, out_features=300, bias=True)\n      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=300, out_features=300, bias=True)\n    ))\n  )\n  (jk): JumpingKnowledge(cat)\n  (lin1): Linear(in_features=1500, out_features=128, bias=True)\n  (lin2): Linear(in_features=128, out_features=12, bias=True)\n)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"jk_optimizer = optim.AdamW(\n    jk_model.parameters(),\n    lr = 1e-3,\n    weight_decay = 5e-4\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:10:12.774497Z","iopub.execute_input":"2025-06-02T20:10:12.774793Z","iopub.status.idle":"2025-06-02T20:10:12.779906Z","shell.execute_reply.started":"2025-06-02T20:10:12.774773Z","shell.execute_reply":"2025-06-02T20:10:12.779023Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"jk_criterion = nn.BCEWithLogitsLoss()\n#jk_criterion = FocalLoss(alpha=0.25, gamma=2.0, reduction='none')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:11:20.664793Z","iopub.execute_input":"2025-06-02T20:11:20.665106Z","iopub.status.idle":"2025-06-02T20:11:20.670475Z","shell.execute_reply.started":"2025-06-02T20:11:20.665084Z","shell.execute_reply":"2025-06-02T20:11:20.669521Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"for epoch in range(1, 26):\n    loss = train_epoch(jk_model, train_loader, jk_optimizer, jk_criterion, device, False)\n    ps_val, ys_val = evaluate(jk_model, val_loader, device, False)\n    ys_val = ys_val.reshape(ps_val.shape)\n    aucs = []\n    for i in range(ps_val.shape[1]):\n        mask = ys_val[:, i] >= 0\n        if mask.sum() > 0:\n            aucs.append(roc_auc_score(ys_val[mask, i], ps_val[mask, i]))\n    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Val AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:11:21.696403Z","iopub.execute_input":"2025-06-02T20:11:21.696950Z","iopub.status.idle":"2025-06-02T20:12:30.757461Z","shell.execute_reply.started":"2025-06-02T20:11:21.696907Z","shell.execute_reply":"2025-06-02T20:12:30.756541Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Loss: 0.2346 | Val AUC: 0.671\nEpoch 02 | Loss: 0.2082 | Val AUC: 0.668\nEpoch 03 | Loss: 0.2039 | Val AUC: 0.681\nEpoch 04 | Loss: 0.2022 | Val AUC: 0.696\nEpoch 05 | Loss: 0.1997 | Val AUC: 0.629\nEpoch 06 | Loss: 0.1983 | Val AUC: 0.690\nEpoch 07 | Loss: 0.1967 | Val AUC: 0.706\nEpoch 08 | Loss: 0.1958 | Val AUC: 0.704\nEpoch 09 | Loss: 0.1932 | Val AUC: 0.689\nEpoch 10 | Loss: 0.1918 | Val AUC: 0.692\nEpoch 11 | Loss: 0.1900 | Val AUC: 0.718\nEpoch 12 | Loss: 0.1906 | Val AUC: 0.716\nEpoch 13 | Loss: 0.1881 | Val AUC: 0.712\nEpoch 14 | Loss: 0.1875 | Val AUC: 0.726\nEpoch 15 | Loss: 0.1868 | Val AUC: 0.717\nEpoch 16 | Loss: 0.1851 | Val AUC: 0.702\nEpoch 17 | Loss: 0.1841 | Val AUC: 0.727\nEpoch 18 | Loss: 0.1848 | Val AUC: 0.711\nEpoch 19 | Loss: 0.1832 | Val AUC: 0.717\nEpoch 20 | Loss: 0.1831 | Val AUC: 0.725\nEpoch 21 | Loss: 0.1809 | Val AUC: 0.718\nEpoch 22 | Loss: 0.1819 | Val AUC: 0.726\nEpoch 23 | Loss: 0.1805 | Val AUC: 0.733\nEpoch 24 | Loss: 0.1796 | Val AUC: 0.719\nEpoch 25 | Loss: 0.1794 | Val AUC: 0.715\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"ps_test, ys_test = evaluate(jk_model, test_loader, device, False)\nys_test = ys_test.reshape(ps_test.shape)\naucs = []\nfor i in range(ps_test.shape[1]):\n    mask = ys_test[:, i] >= 0\n    if mask.sum() > 0:\n        aucs.append(roc_auc_score(ys_test[mask, i], ps_test[mask, i]))\nprint(f\"Testing | Loss: {loss:.4f} | Test AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:13:35.918448Z","iopub.execute_input":"2025-06-02T20:13:35.919402Z","iopub.status.idle":"2025-06-02T20:13:36.197909Z","shell.execute_reply.started":"2025-06-02T20:13:35.919372Z","shell.execute_reply":"2025-06-02T20:13:36.197109Z"}},"outputs":[{"name":"stdout","text":"Testing | Loss: 0.1794 | Test AUC: 0.711\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### Try Adding Quantum Computing","metadata":{}},{"cell_type":"code","source":"def QLinearCircuit(dev, num_qubits):\n    def func(inputs, weights):\n        AngleEmbedding(\n            features=inputs,\n            wires=range(num_qubits),\n            rotation='Y'\n        )\n        StronglyEntanglingLayers(\n            weights=weights,\n            wires=range(num_qubits),\n            imprimitive=qml.CNOT,\n        )\n        return [qml.expval(qml.PauliZ(w)) for w in range(num_qubits)]\n\n    qn = qml.QNode(func, dev, interface='torch')\n    #qml.add_noise(qn, noise_model = model_pl)\n    return qml.qnn.TorchLayer(qn, {\"weights\": (1, num_qubits, 3)})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:33:01.070880Z","iopub.execute_input":"2025-06-02T20:33:01.071201Z","iopub.status.idle":"2025-06-02T20:33:01.077306Z","shell.execute_reply.started":"2025-06-02T20:33:01.071179Z","shell.execute_reply":"2025-06-02T20:33:01.076242Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"class QReLU(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.C1 = torch.tensor(0.01)\n        self.C2 = torch.tensor(2)\n\n    def forward(self, x):\n        return torch.where(\n            x <= 0,\n            self.C1 * x - self.C2 * x,\n            x\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:33:01.563223Z","iopub.execute_input":"2025-06-02T20:33:01.564182Z","iopub.status.idle":"2025-06-02T20:33:01.568906Z","shell.execute_reply.started":"2025-06-02T20:33:01.564151Z","shell.execute_reply":"2025-06-02T20:33:01.568017Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"class SmallQNN(nn.Module):\n    def __init__(self, num_qubits: int):\n        super().__init__()\n        qdev = qml.device(\n            \"default.qubit\",\n            wires=num_qubits,\n            #shots=256,\n        )\n        self.qfunc = QLinearCircuit(qdev, num_qubits)\n        self.qrelu = QReLU()\n        self.bn_gate = nn.BatchNorm1d(num_qubits)\n        self.in_channels = num_qubits\n\n    def forward(self, inputs):\n        x = self.qfunc(inputs)\n        x = self.bn_gate(x)\n        return self.qrelu(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:36:54.437271Z","iopub.execute_input":"2025-06-02T20:36:54.437623Z","iopub.status.idle":"2025-06-02T20:36:54.443025Z","shell.execute_reply.started":"2025-06-02T20:36:54.437580Z","shell.execute_reply":"2025-06-02T20:36:54.442077Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"class GINEWithQNN(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,\n        hidden_dim: int,\n        num_tasks: int,\n        n_layers: int,\n    ):\n        super().__init__()\n        self.n_layers = n_layers\n        self.qnn = SmallQNN(num_qubits=input_dim)\n\n        # first GINE\n        self.conv1 = GINEConv(\n            nn.Sequential(\n                nn.Linear(input_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            ),\n            edge_dim=8,\n        )\n\n        # additional GINE layers\n        self.convs = nn.ModuleList()\n        for _ in range(n_layers-1):\n            mlp = nn.Sequential(\n                nn.Linear(hidden_dim, hidden_dim),\n                nn.BatchNorm1d(hidden_dim),\n                nn.ReLU(),\n                nn.Linear(hidden_dim, hidden_dim),\n            )\n            self.convs.append(GINEConv(mlp, edge_dim=8))\n\n        # final FC — input dim doubles due to Set2Set concat\n        self.fc = nn.Linear(hidden_dim, num_tasks)\n\n    def forward(self, x, edge_index, edge_attr, batch):\n        x = self.qnn(x) # qnn\n\n        # Initial GINEConv Layer\n        x = F.relu(self.conv1(x, edge_index, edge_attr)) \n\n        # Main GINEConv Layers\n        for conv in self.convs:\n            x = F.relu(conv(x, edge_index, edge_attr))\n\n        # Pooling\n        x = global_mean_pool(x, batch)\n\n        # Final prediction\n        return self.fc(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:37:19.363948Z","iopub.execute_input":"2025-06-02T20:37:19.364247Z","iopub.status.idle":"2025-06-02T20:37:19.372055Z","shell.execute_reply.started":"2025-06-02T20:37:19.364225Z","shell.execute_reply":"2025-06-02T20:37:19.371064Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"qnn_model = GINEWithQNN(\n    in_channels,\n    hidden_dim = 300,\n    num_tasks = num_tasks,\n    n_layers = 5,\n).to(device)\n\nprint(qnn_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:37:19.860189Z","iopub.execute_input":"2025-06-02T20:37:19.860504Z","iopub.status.idle":"2025-06-02T20:37:19.897744Z","shell.execute_reply.started":"2025-06-02T20:37:19.860483Z","shell.execute_reply":"2025-06-02T20:37:19.896918Z"}},"outputs":[{"name":"stdout","text":"GINEWithQNN(\n  (qnn): SmallQNN(\n    (qfunc): <Quantum Torch Layer: func=func>\n    (qrelu): QReLU()\n    (bn_gate): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (conv1): GINEConv(nn=Sequential(\n    (0): Linear(in_features=7, out_features=300, bias=True)\n    (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Linear(in_features=300, out_features=300, bias=True)\n  ))\n  (convs): ModuleList(\n    (0-3): 4 x GINEConv(nn=Sequential(\n      (0): Linear(in_features=300, out_features=300, bias=True)\n      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Linear(in_features=300, out_features=300, bias=True)\n    ))\n  )\n  (fc): Linear(in_features=300, out_features=12, bias=True)\n)\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"qnn_optimizer = optim.AdamW(\n    qnn_model.parameters(),\n    lr=1e-3,\n    weight_decay=5e-4,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:37:19.978677Z","iopub.execute_input":"2025-06-02T20:37:19.978984Z","iopub.status.idle":"2025-06-02T20:37:19.983760Z","shell.execute_reply.started":"2025-06-02T20:37:19.978962Z","shell.execute_reply":"2025-06-02T20:37:19.982642Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"qnn_criterion = FocalLoss(alpha=0.25, gamma=2.1, reduction='none')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:37:22.227793Z","iopub.execute_input":"2025-06-02T20:37:22.228101Z","iopub.status.idle":"2025-06-02T20:37:22.232409Z","shell.execute_reply.started":"2025-06-02T20:37:22.228079Z","shell.execute_reply":"2025-06-02T20:37:22.231631Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"for epoch in range(1, 31):\n    loss = train_epoch(qnn_model, train_loader, qnn_optimizer, qnn_criterion, device, False)\n    ps_val, ys_val = evaluate(qnn_model, val_loader, device, False)\n    ys_val = ys_val.reshape(ps_val.shape)\n    aucs = []\n    for i in range(ps_val.shape[1]):\n        mask = ys_val[:, i] >= 0\n        if mask.sum() > 0:\n            aucs.append(roc_auc_score(ys_val[mask, i], ps_val[mask, i]))\n    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Val AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:37:22.974740Z","iopub.execute_input":"2025-06-02T20:37:22.975036Z","iopub.status.idle":"2025-06-02T20:43:06.419230Z","shell.execute_reply.started":"2025-06-02T20:37:22.975015Z","shell.execute_reply":"2025-06-02T20:43:06.418420Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Loss: 0.0200 | Val AUC: 0.655\nEpoch 02 | Loss: 0.0181 | Val AUC: 0.673\nEpoch 03 | Loss: 0.0178 | Val AUC: 0.681\nEpoch 04 | Loss: 0.0175 | Val AUC: 0.699\nEpoch 05 | Loss: 0.0173 | Val AUC: 0.698\nEpoch 06 | Loss: 0.0171 | Val AUC: 0.682\nEpoch 07 | Loss: 0.0169 | Val AUC: 0.684\nEpoch 08 | Loss: 0.0169 | Val AUC: 0.671\nEpoch 09 | Loss: 0.0167 | Val AUC: 0.704\nEpoch 10 | Loss: 0.0166 | Val AUC: 0.682\nEpoch 11 | Loss: 0.0165 | Val AUC: 0.704\nEpoch 12 | Loss: 0.0165 | Val AUC: 0.715\nEpoch 13 | Loss: 0.0162 | Val AUC: 0.698\nEpoch 14 | Loss: 0.0162 | Val AUC: 0.683\nEpoch 15 | Loss: 0.0161 | Val AUC: 0.702\nEpoch 16 | Loss: 0.0160 | Val AUC: 0.709\nEpoch 17 | Loss: 0.0160 | Val AUC: 0.694\nEpoch 18 | Loss: 0.0157 | Val AUC: 0.704\nEpoch 19 | Loss: 0.0157 | Val AUC: 0.711\nEpoch 20 | Loss: 0.0156 | Val AUC: 0.710\nEpoch 21 | Loss: 0.0156 | Val AUC: 0.713\nEpoch 22 | Loss: 0.0153 | Val AUC: 0.714\nEpoch 23 | Loss: 0.0154 | Val AUC: 0.726\nEpoch 24 | Loss: 0.0153 | Val AUC: 0.708\nEpoch 25 | Loss: 0.0153 | Val AUC: 0.711\nEpoch 26 | Loss: 0.0151 | Val AUC: 0.718\nEpoch 27 | Loss: 0.0150 | Val AUC: 0.715\nEpoch 28 | Loss: 0.0150 | Val AUC: 0.710\nEpoch 29 | Loss: 0.0148 | Val AUC: 0.720\nEpoch 30 | Loss: 0.0146 | Val AUC: 0.713\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"ps_test, ys_test = evaluate(qnn_model, test_loader, device, False)\nys_test = ys_test.reshape(ps_test.shape)\naucs = []\nfor i in range(ps_test.shape[1]):\n    mask = ys_test[:, i] >= 0\n    if mask.sum() > 0:\n        aucs.append(roc_auc_score(ys_test[mask, i], ps_test[mask, i]))\nprint(f\"Testing | Loss: {loss:.4f} | Test AUC: {np.mean(aucs):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:44:21.790060Z","iopub.execute_input":"2025-06-02T20:44:21.790830Z","iopub.status.idle":"2025-06-02T20:44:22.573155Z","shell.execute_reply.started":"2025-06-02T20:44:21.790806Z","shell.execute_reply":"2025-06-02T20:44:22.572373Z"}},"outputs":[{"name":"stdout","text":"Testing | Loss: 0.0146 | Test AUC: 0.696\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}